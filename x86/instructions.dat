ADC—Add
14 ib                                   |ADC AL, imm8
15 iw                                   |ADC AX, imm16
15 id                                   |ADC EAX, imm32
REX.W + 15 id                           |ADC RAX, imm32
80 /2 ib                                |ADC r/m8, imm8
REX + 80 /2 ib                          |ADC r/m8 , imm8
81 /2 iw                                |ADC r/m16, imm16
81 /2 id                                |ADC r/m32, imm32
REX.W + 81 /2 id                        |ADC r/m64, imm32
83 /2 ib                                |ADC r/m16, imm8
83 /2 ib                                |ADC r/m32, imm8
REX.W + 83 /2 ib                        |ADC r/m64, imm8
10 /r                                   |ADC r/m8, r8
REX + 10 /r                             |ADC r/m8 , r8
11 /r                                   |ADC r/m16, r16
11 /r                                   |ADC r/m32, r32
REX.W + 11 /r                           |ADC r/m64, r64
12 /r                                   |ADC r8, r/m8
REX + 12 /r                             |ADC r8 , r/m8
13 /r                                   |ADC r16, r/m16
13 /r                                   |ADC r32, r/m32
REX.W + 13 /r                           |ADC r64, r/m64
ADCX—Unsigned
66 0F 38 F6 /r                          |ADCX r32, r/m32
66 REX.w 0F 38 F6 /r                    |ADCX r64, r/m64
ADD—Add
04 ib                                   |ADD AL, imm8
05 iw                                   |ADD AX, imm16
05 id                                   |ADD EAX, imm32
REX.W + 05 id                           |ADD RAX, imm32
80 /0 ib                                |ADD r/m8, imm8
REX + 80 /0 ib                          |ADD r/m8 , imm8
81 /0 iw                                |ADD r/m16, imm16
81 /0 id                                |ADD r/m32, imm32
REX.W + 81 /0 id                        |ADD r/m64, imm32
83 /0 ib                                |ADD r/m16, imm8
83 /0 ib                                |ADD r/m32, imm8
REX.W + 83 /0 ib                        |ADD r/m64, imm8
00 /r                                   |ADD r/m8, r8
REX + 00 /r                             |ADD r/m8 , r8
01 /r                                   |ADD r/m16, r16
01 /r                                   |ADD r/m32, r32
REX.W + 01 /r                           |ADD r/m64, r64
02 /r                                   |ADD r8, r/m8
REX + 02 /r                             |ADD r8 , r/m8
03 /r                                   |ADD r16, r/m16
03 /r                                   |ADD r32, r/m32
REX.W + 03 /r                           |ADD r64, r/m64
ADDPD—Add
66 0F 58 /r                             |ADDPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 58 /r                 |VADDPD xmm1,xmm2,xmm3/m128
VEX.256.66.0F.WIG 58 /r                 |VADDPD ymm1, ymm2,ymm3/m256
ADDPS—Add
NP 0F 58 /r                             |ADDPS xmm1, xmm2/m128
VEX.128.0F.WIG 58 /r                    |VADDPS xmm1,xmm2, xmm3/m128
VEX.256.0F.WIG 58 /r                    |VADDPS ymm1, ymm2, ymm3/m256
ADDSD—Add
F2 0F 58 /r                             |ADDSD xmm1, xmm2/m64
VEX.LIG.F2.0F.WIG 58 /r                 |VADDSD xmm1, xmm2,xmm3/m64
ADDSS—Add
F3 0F 58 /r                             |ADDSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 58 /r                 |VADDSS xmm1,xmm2,xmm3/m32
ADDSUBPD—Packed
66 0F D0 /r                             |ADDSUBPD xmm1, xmm2/m128
VEX.128.66.0F.WIG D0 /r                 |VADDSUBPD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG D0 /r                 |VADDSUBPD ymm1, ymm2, ymm3/m256
ADDSUBPS—Packed
F2 0F D0 /r                             |ADDSUBPS xmm1, xmm2/m128
VEX.128.F2.0F.WIG D0 /r                 |VADDSUBPS xmm1, xmm2, xmm3/m128
VEX.256.F2.0F.WIG D0 /r                 |VADDSUBPS ymm1, ymm2, ymm3/m256
AESDEC—Perform
66 0F 38 DE /r                          |AESDEC xmm1, xmm2/m128
VEX.128.66.0F38.WIG DE /r               |VAESDEC xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG DE /r               |VAESDEC ymm1, ymm2, ymm3/m256
AESDEC128KL—Perform
F3 0F 38 DD !(11):rrr:bbb               |AESDEC128KL xmm, m384
AESDEC256KL—Perform
F3 0F 38 DF !(11):rrr:bbb               |AESDEC256KL xmm, m512
AESDECLAST—Perform
66 0F 38 DF /r                          |AESDECLAST xmm1, xmm2/m128
VEX.128.66.0F38.WIG DF /r               |VAESDECLAST xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG DF /r               |VAESDECLAST ymm1, ymm2, ymm3/m256
AESDECWIDE128KL—Perform
F3 0F 38 D8 !(11):001:bbb               |AESDECWIDE128KL m384, <XMM0-7>
AESDECWIDE256KL—Perform
F3 0F 38 D8 !(11):011:bbb               |AESDECWIDE256KL m512, <XMM0-7>
AESENC—Perform
66 0F 38 DC /r                          |AESENC xmm1, xmm2/m128
VEX.128.66.0F38.WIG DC /r               |VAESENC xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG DC /r               |VAESENC ymm1, ymm2, ymm3/m256
AESENC128KL—Perform
F3 0F 38 DC !(11):rrr:bbb               |AESENC128KL xmm, m384
AESENC256KL—Perform
F3 0F 38 DE !(11):rrr:bbb               |AESENC256KL xmm, m512
AESENCLAST—Perform
66 0F 38 DD /r                          |AESENCLAST xmm1, xmm2/m128
VEX.128.66.0F38.WIG DD /r               |VAESENCLAST xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG DD /r               |VAESENCLAST ymm1, ymm2, ymm3/m256
AESENCWIDE128KL—Perform
F3 0F 38 D8 !(11):000:bbb               |AESENCWIDE128KL m384, <XMM0-7>
AESENCWIDE256KL—Perform
F3 0F 38 D8 !(11):010:bbb               |AESENCWIDE256KL m512, <XMM0-7>
AESIMC—Perform
66 0F 38 DB /r                          |AESIMC xmm1, xmm2/m128
VEX.128.66.0F38.WIG DB /r               |VAESIMC xmm1, xmm2/m128
AESKEYGENASSIST—AES
66 0F 3A DF /r ib                       |AESKEYGENASSIST xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG DF /r ib            |VAESKEYGENASSIST xmm1, xmm2/m128, imm8
AND—Logical
24 ib                                   |AND AL, imm8
25 iw                                   |AND AX, imm16
25 id                                   |AND EAX, imm32
REX.W + 25 id                           |AND RAX, imm32
80 /4 ib                                |AND r/m8, imm8
REX + 80 /4 ib                          |AND r/m8 , imm8
81 /4 iw                                |AND r/m16, imm16
81 /4 id                                |AND r/m32, imm32
REX.W + 81 /4 id                        |AND r/m64, imm32
83 /4 ib                                |AND r/m16, imm8
83 /4 ib                                |AND r/m32, imm8
REX.W + 83 /4 ib                        |AND r/m64, imm8
20 /r                                   |AND r/m8, r8
REX + 20 /r                             |AND r/m8 , r8
21 /r                                   |AND r/m16, r16
21 /r                                   |AND r/m32, r32
REX.W + 21 /r                           |AND r/m64, r64
22 /r                                   |AND r8, r/m8
REX + 22 /r                             |AND r8 , r/m8
23 /r                                   |AND r16, r/m16
23 /r                                   |AND r32, r/m32
REX.W + 23 /r                           |AND r64, r/m64
ANDN—Logical
VEX.LZ.0F38.W0 F2 /r                    |ANDN r32a, r32b, r/m32
VEX.LZ. 0F38.W1 F2 /r                   |ANDN r64a, r64b, r/m64
ANDPD—Bitwise
66 0F 54 /r                             |ANDPD xmm1, xmm2/m128
VEX.128.66.0F 54 /r                     |VANDPD xmm1, xmm2, xmm3/m128
VEX.256.66.0F 54 /r                     |VANDPD ymm1, ymm2, ymm3/m256
ANDPS—Bitwise
NP 0F 54 /r                             |ANDPS xmm1, xmm2/m128
VEX.128.0F 54 /r                        |VANDPS xmm1,xmm2,xmm3/m128
VEX.256.0F 54 /r                        |VANDPS ymm1, ymm2,ymm3/m256
ANDNPD—Bitwise
66 0F 55 /r                             |ANDNPD xmm1, xmm2/m128
VEX.128.66.0F 55 /r                     |VANDNPD xmm1, xmm2,xmm3/m128
VEX.256.66.0F 55/r                      |VANDNPD ymm1, ymm2,ymm3/m256
ANDNPS—Bitwise
NP 0F 55 /r                             |ANDNPS xmm1, xmm2/m128
VEX.128.0F 55 /r                        |VANDNPS xmm1, xmm2,xmm3/m128
VEX.256.0F 55 /r                        |VANDNPS ymm1, ymm2,ymm3/m256
BEXTR—Bit
VEX.LZ.0F38.W0 F7 /r                    |BEXTR r32a, r/m32, r32b
VEX.LZ.0F38.W1 F7 /r                    |BEXTR r64a, r/m64, r64b
BLENDPD—Blend
66 0F 3A 0D /r ib                       |BLENDPD xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 0D /r ib            |VBLENDPD xmm1, xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.WIG 0D /r ib            |VBLENDPD ymm1, ymm2, ymm3/m256, imm8
BLENDPS—Blend
66 0F 3A 0C /r ib                       |BLENDPS xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 0C /r ib            |VBLENDPS xmm1, xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.WIG 0C /r ib            |VBLENDPS ymm1, ymm2, ymm3/m256, imm8
BLENDVPD—Variable
66 0F 38 15 /r                          |BLENDVPD xmm1, xmm2/m128 , <XMM0>
VEX.128.66.0F3A.W0 4B /r /is4           |VBLENDVPD xmm1, xmm2, xmm3/m128, xmm4
VEX.256.66.0F3A.W0 4B /r /is4           |VBLENDVPD ymm1, ymm2, ymm3/m256, ymm4
BLENDVPS—Variable
66 0F 38 14 /r                          |BLENDVPS xmm1, xmm2/m128, <XMM0>
VEX.128.66.0F3A.W0 4A /r /is4           |VBLENDVPS xmm1, xmm2, xmm3/m128, xmm4
VEX.256.66.0F3A.W0 4A /r /is4           |VBLENDVPS ymm1, ymm2, ymm3/m256, ymm4
BLSI—Extract
VEX.LZ.0F38.W0 F3 /3                    |BLSI r32, r/m32
VEX.LZ.0F38.W1 F3 /3                    |BLSI r64, r/m64
BLSMSK—Get
VEX.LZ.0F38.W0 F3 /2                    |BLSMSK r32, r/m32
VEX.LZ.0F38.W1 F3 /2                    |BLSMSK r64, r/m64
BLSR—Reset
VEX.LZ.0F38.W0 F3 /1                    |BLSR r32, r/m32
VEX.LZ.0F38.W1 F3 /1                    |BLSR r64, r/m64
BNDCL—Check
F3 0F 1A /r                             |BNDCL bnd, r/m64
BNDCU/BNDCN—Check
F2 0F 1A /r                             |BNDCU bnd, r/m64
F2 0F 1B /r                             |BNDCN bnd, r/m64
BNDLDX—Load
NP 0F 1A /r                             |BNDLDX bnd, mib
BNDMK—Make
F3 0F 1B /r                             |BNDMK bnd, m64
BNDMOV—Move
66 0F 1A /r                             |BNDMOV bnd1, bnd2/m128
66 0F 1B /r                             |BNDMOV bnd1/m128, bnd2
BNDSTX—Store
NP 0F 1B /r                             |BNDSTX mib, bnd
BSF—Bit
0F BC /r                                |BSF r16, r/m16
0F BC /r                                |BSF r32, r/m32
REX.W + 0F BC /r                        |BSF r64, r/m64
BSR—Bit
0F BD /r                                |BSR r16, r/m16
0F BD /r                                |BSR r32, r/m32
REX.W + 0F BD /r                        |BSR r64, r/m64
BSWAP—Byte
0F C8+rd                                |BSWAP r32
REX.W + 0F C8+rd                        |BSWAP r64
BT—Bit
0F A3 /r                                |BT r/m16, r16
0F A3 /r                                |BT r/m32, r32
REX.W + 0F A3 /r                        |BT r/m64, r64
0F BA /4 ib                             |BT r/m16, imm8
0F BA /4 ib                             |BT r/m32, imm8
REX.W + 0F BA /4 ib                     |BT r/m64, imm8
BTC—Bit
0F BB /r                                |BTC r/m16, r16
0F BB /r                                |BTC r/m32, r32
REX.W + 0F BB /r                        |BTC r/m64, r64
0F BA /7 ib                             |BTC r/m16, imm8
0F BA /7 ib                             |BTC r/m32, imm8
REX.W + 0F BA /7 ib                     |BTC r/m64, imm8
BTR—Bit
0F B3 /r                                |BTR r/m16, r16
0F B3 /r                                |BTR r/m32, r32
REX.W + 0F B3 /r                        |BTR r/m64, r64
0F BA /6 ib                             |BTR r/m16, imm8
0F BA /6 ib                             |BTR r/m32, imm8
REX.W + 0F BA /6 ib                     |BTR r/m64, imm8
BTS—Bit
0F AB /r                                |BTS r/m16, r16
0F AB /r                                |BTS r/m32, r32
REX.W + 0F AB /r                        |BTS r/m64, r64
0F BA /5 ib                             |BTS r/m16, imm8
0F BA /5 ib                             |BTS r/m32, imm8
REX.W + 0F BA /5 ib                     |BTS r/m64, imm8
BZHI—Zero
VEX.LZ.0F38.W0 F5 /r                    |BZHI r32a, r/m32, r32b
VEX.LZ.0F38.W1 F5 /r                    |BZHI r64a, r/m64, r64b
CALL—Call
E8 cd                                   |CALL rel32
FF /2                                   |CALL r/m64
FF /3                                   |CALL m16:16
FF /3                                   |CALL m16:32
REX.W FF /3                             |CALL m16:64
CBW/CWDE/CDQE—Convert
98                                      |CBW
98                                      |CWDE
REX.W + 98                              |CDQE
CLAC—Clear
NP 0F 01 CA                             |CLAC
CLC—Clear
F8                                      |CLC
CLD—Clear
FC                                      |CLD
CLDEMOTE—Cache
NP 0F 1C /0                             |CLDEMOTE m8
CLFLUSH—Flush
NP 0F AE /7                             |CLFLUSH m8
CLFLUSHOPT—Flush
NFx 66 0F AE /7                         |CLFLUSHOPT m8
CLI—Clear
FA                                      |CLI
CLRSSBSY—Clear
F3 0F AE /6                             |CLRSSBSY m64
CLTS—Clear
0F 06                                   |CLTS
CLUI—Clear
F3 0F 01 EE                             |CLUI
CLWB—Cache
66 0F AE /6                             |CLWB m8
CMC—Complement
F5                                      |CMC
CMOVcc—Conditional
0F 47 /r                                |CMOVA r16, r/m16
0F 47 /r                                |CMOVA r32, r/m32
REX.W + 0F 47 /r                        |CMOVA r64, r/m64
0F 43 /r                                |CMOVAE r16, r/m16
0F 43 /r                                |CMOVAE r32, r/m32
REX.W + 0F 43 /r                        |CMOVAE r64, r/m64
0F 42 /r                                |CMOVB r16, r/m16
0F 42 /r                                |CMOVB r32, r/m32
REX.W + 0F 42 /r                        |CMOVB r64, r/m64
0F 46 /r                                |CMOVBE r16, r/m16
0F 46 /r                                |CMOVBE r32, r/m32
REX.W + 0F 46 /r                        |CMOVBE r64, r/m64
0F 42 /r                                |CMOVC r16, r/m16
0F 42 /r                                |CMOVC r32, r/m32
REX.W + 0F 42 /r                        |CMOVC r64, r/m64
0F 44 /r                                |CMOVE r16, r/m16
0F 44 /r                                |CMOVE r32, r/m32
REX.W + 0F 44 /r                        |CMOVE r64, r/m64
0F 4F /r                                |CMOVG r16, r/m16
0F 4F /r                                |CMOVG r32, r/m32
REX.W + 0F 4F /r                        |CMOVG r64, r/m64
0F 4D /r                                |CMOVGE r16, r/m16
0F 4D /r                                |CMOVGE r32, r/m32
REX.W + 0F 4D /r                        |CMOVGE r64, r/m64
0F 4C /r                                |CMOVL r16, r/m16
0F 4C /r                                |CMOVL r32, r/m32
REX.W + 0F 4C /r                        |CMOVL r64, r/m64
0F 4E /r                                |CMOVLE r16, r/m16
0F 4E /r                                |CMOVLE r32, r/m32
REX.W + 0F 4E /r                        |CMOVLE r64, r/m64
0F 46 /r                                |CMOVNA r16, r/m16
0F 46 /r                                |CMOVNA r32, r/m32
REX.W + 0F 46 /r                        |CMOVNA r64, r/m64
0F 42 /r                                |CMOVNAE r16, r/m16
0F 42 /r                                |CMOVNAE r32, r/m32
REX.W + 0F 42 /r                        |CMOVNAE r64, r/m64
0F 43 /r                                |CMOVNB r16, r/m16
0F 43 /r                                |CMOVNB r32, r/m32
REX.W + 0F 43 /r                        |CMOVNB r64, r/m64
0F 47 /r                                |CMOVNBE r16, r/m16
CMOVcc—Conditional
0F 47 /r                                |CMOVNBE r32, r/m32
REX.W + 0F 47 /r                        |CMOVNBE r64, r/m64
0F 43 /r                                |CMOVNC r16, r/m16
0F 43 /r                                |CMOVNC r32, r/m32
REX.W + 0F 43 /r                        |CMOVNC r64, r/m64
0F 45 /r                                |CMOVNE r16, r/m16
0F 45 /r                                |CMOVNE r32, r/m32
REX.W + 0F 45 /r                        |CMOVNE r64, r/m64
0F 4E /r                                |CMOVNG r16, r/m16
0F 4E /r                                |CMOVNG r32, r/m32
REX.W + 0F 4E /r                        |CMOVNG r64, r/m64
0F 4C /r                                |CMOVNGE r16, r/m16
0F 4C /r                                |CMOVNGE r32, r/m32
REX.W + 0F 4C /r                        |CMOVNGE r64, r/m64
0F 4D /r                                |CMOVNL r16, r/m16
0F 4D /r                                |CMOVNL r32, r/m32
REX.W + 0F 4D /r                        |CMOVNL r64, r/m64
0F 4F /r                                |CMOVNLE r16, r/m16
0F 4F /r                                |CMOVNLE r32, r/m32
REX.W + 0F 4F /r                        |CMOVNLE r64, r/m64
0F 41 /r                                |CMOVNO r16, r/m16
0F 41 /r                                |CMOVNO r32, r/m32
REX.W + 0F 41 /r                        |CMOVNO r64, r/m64
0F 4B /r                                |CMOVNP r16, r/m16
0F 4B /r                                |CMOVNP r32, r/m32
REX.W + 0F 4B /r                        |CMOVNP r64, r/m64
0F 49 /r                                |CMOVNS r16, r/m16
0F 49 /r                                |CMOVNS r32, r/m32
REX.W + 0F 49 /r                        |CMOVNS r64, r/m64
0F 45 /r                                |CMOVNZ r16, r/m16
0F 45 /r                                |CMOVNZ r32, r/m32
REX.W + 0F 45 /r                        |CMOVNZ r64, r/m64
0F 40 /r                                |CMOVO r16, r/m16
0F 40 /r                                |CMOVO r32, r/m32
REX.W + 0F 40 /r                        |CMOVO r64, r/m64
0F 4A /r                                |CMOVP r16, r/m16
0F 4A /r                                |CMOVP r32, r/m32
REX.W + 0F 4A /r                        |CMOVP r64, r/m64
0F 4A /r                                |CMOVPE r16, r/m16
0F 4A /r                                |CMOVPE r32, r/m32
REX.W + 0F 4A /r                        |CMOVPE r64, r/m64
CMOVcc—Conditional
0F 4B /r                                |CMOVPO r16, r/m16
0F 4B /r                                |CMOVPO r32, r/m32
REX.W + 0F 4B /r                        |CMOVPO r64, r/m64
0F 48 /r                                |CMOVS r16, r/m16
0F 48 /r                                |CMOVS r32, r/m32
REX.W + 0F 48 /r                        |CMOVS r64, r/m64
0F 44 /r                                |CMOVZ r16, r/m16
0F 44 /r                                |CMOVZ r32, r/m32
REX.W + 0F 44 /r                        |CMOVZ r64, r/m64
CMP—Compare
3C ib                                   |CMP AL, imm8
3D iw                                   |CMP AX, imm16
3D id                                   |CMP EAX, imm32
REX.W + 3D id                           |CMP RAX, imm32
80 /7 ib                                |CMP r/m8, imm8
REX + 80 /7 ib                          |CMP r/m8 , imm8
81 /7 iw                                |CMP r/m16, imm16
81 /7 id                                |CMP r/m32, imm32
REX.W + 81 /7 id                        |CMP r/m64, imm32
83 /7 ib                                |CMP r/m16, imm8
83 /7 ib                                |CMP r/m32, imm8
REX.W + 83 /7 ib                        |CMP r/m64, imm8
38 /r                                   |CMP r/m8, r8
REX + 38 /r                             |CMP r/m8 , r8
39 /r                                   |CMP r/m16, r16
39 /r                                   |CMP r/m32, r32
REX.W + 39 /r                           |CMP r/m64,r64
3A /r                                   |CMP r8, r/m8
REX + 3A /r                             |CMP r8 , r/m8
3B /r                                   |CMP r16, r/m16
3B /r                                   |CMP r32, r/m32
REX.W + 3B /r                           |CMP r64, r/m64
CMPPD—Compare
66 0F C2 /r ib                          |CMPPD xmm1, xmm2/m128, imm8
VEX.128.66.0F.WIG C2 /r ib              |VCMPPD xmm1, xmm2, xmm3/m128,imm8
VEX.256.66.0F.WIG C2 /r ib              |VCMPPD ymm1, ymm2, ymm3/m256,imm8
CMPPS—Compare
NP 0F C2 /r ib                          |CMPPS xmm1, xmm2/m128, imm8
VEX.128.0F.WIG C2 /r ib                 |VCMPPS xmm1, xmm2,xmm3/m128, imm8
VEX.256.0F.WIG C2 /r ib                 |VCMPPS ymm1, ymm2,ymm3/m256, imm8
CMPS/CMPSB/CMPSW/CMPSD/CMPSQ—Compare
A6                                      |CMPS m8, m8
A7                                      |CMPS m16, m16
A7                                      |CMPS m32, m32
REX.W + A7                              |CMPS m64, m64
A6                                      |CMPSB
A7                                      |CMPSW
A7                                      |CMPSD
REX.W + A7                              |CMPSQ
CMPSD—Compare
F2 0F C2 /r ib                          |CMPSD xmm1, xmm2/m64, imm8
VEX.LIG.F2.0F.WIG C2 /r ib              |VCMPSD xmm1, xmm2, xmm3/m64,imm8
CMPSS—Compare
F3 0F C2 /r ib                          |CMPSS xmm1, xmm2/m32, imm8
VEX.LIG.F3.0F.WIG C2 /r ib              |VCMPSS xmm1, xmm2, xmm3/m32,imm8
CMPXCHG—Compare
0F B0/r                                 |CMPXCHG r/m8, r8
REX + 0F B0/r                           |CMPXCHG r/m8,r8
0F B1/r                                 |CMPXCHG r/m16, r16
0F B1/r                                 |CMPXCHG r/m32, r32
REX.W + 0F B1/r                         |CMPXCHG r/m64, r64
CMPXCHG8B/CMPXCHG16B—Compare
0F C7 /1                                |CMPXCHG8B m64
REX.W + 0F C7 /1                        |CMPXCHG16B m128
COMISD—Compare
66 0F 2F /r                             |COMISD xmm1, xmm2/m64
VEX.LIG.66.0F.WIG 2F /r                 |VCOMISD xmm1, xmm2/m64
COMISS—Compare
NP 0F 2F /r                             |COMISS xmm1, xmm2/m32
VEX.LIG.0F.WIG 2F /r                    |VCOMISS xmm1, xmm2/m32
CPUID—CPU
0F A2                                   |CPUID
CRC32—Accumulate
F2 0F 38 F0 /r                          |CRC32 r32, r/m8
F2 REX 0F 38 F0 /r                      |CRC32 r32, r/m8
F2 0F 38 F1 /r                          |CRC32 r32, r/m16
F2 0F 38 F1 /r                          |CRC32 r32, r/m32
F2 REX.W 0F 38 F0 /r                    |CRC32 r64, r/m8
F2 REX.W 0F 38 F1 /r                    |CRC32 r64, r/m64
CVTDQ2PD—Convert
F3 0F E6 /r                             |CVTDQ2PD xmm1, xmm2/m64
VEX.128.F3.0F.WIG E6 /r                 |VCVTDQ2PD xmm1, xmm2/m64
VEX.256.F3.0F.WIG E6 /r                 |VCVTDQ2PD ymm1, xmm2/m128
CVTPD2PI—Convert
66 0F 2D /r                             |CVTPD2PI mm, xmm/m128
CVTPD2PS—Convert
66 0F 5A /r                             |CVTPD2PS xmm1, xmm2/m128
VEX.128.66.0F.WIG 5A /r                 |VCVTPD2PS xmm1, xmm2/m128
VEX.256.66.0F.WIG 5A /r                 |VCVTPD2PS xmm1, ymm2/m256
CVTPI2PD—Convert
66 0F 2A /r                             |CVTPI2PD xmm, mm/m64
CVTPI2PS—Convert
NP 0F 2A /r                             |CVTPI2PS xmm, mm/m64
CVTPS2DQ—Convert
66 0F 5B /r                             |CVTPS2DQ xmm1, xmm2/m128
VEX.128.66.0F.WIG 5B /r                 |VCVTPS2DQ xmm1, xmm2/m128
VEX.256.66.0F.WIG 5B /r                 |VCVTPS2DQ ymm1, ymm2/m256
CVTPS2PD—Convert
NP 0F 5A /r                             |CVTPS2PD xmm1, xmm2/m64
VEX.128.0F.WIG 5A /r                    |VCVTPS2PD xmm1, xmm2/m64
VEX.256.0F.WIG 5A /r                    |VCVTPS2PD ymm1, xmm2/m128
CVTPS2PI—Convert
NP 0F 2D /r                             |CVTPS2PI mm, xmm/m64
CVTSD2SI—Convert
F2 0F 2D /r                             |CVTSD2SI r32, xmm1/m64
F2 REX.W 0F 2D /r                       |CVTSD2SI r64, xmm1/m64
VEX.LIG.F2.0F.W0 2D /r 1                |VCVTSD2SI r32, xmm1/m64
VEX.LIG.F2.0F.W1 2D /r 1                |VCVTSD2SI r64, xmm1/m64
CVTSD2SS—Convert
F2 0F 5A /r                             |CVTSD2SS xmm1, xmm2/m64
VEX.LIG.F2.0F.WIG 5A /r                 |VCVTSD2SS xmm1,xmm2, xmm3/m64
CVTSI2SD—Convert
F2 0F 2A /r                             |CVTSI2SD xmm1, r32/m32
F2 REX.W 0F 2A /r                       |CVTSI2SD xmm1, r/m64
VEX.LIG.F2.0F.W0 2A /r                  |VCVTSI2SD xmm1, xmm2, r/m32
VEX.LIG.F2.0F.W1 2A /r                  |VCVTSI2SD xmm1, xmm2, r/m64
CVTSI2SS—Convert
F3 0F 2A /r                             |CVTSI2SS xmm1, r/m32
F3 REX.W 0F 2A /r                       |CVTSI2SS xmm1, r/m64
VEX.LIG.F3.0F.W0 2A /r                  |VCVTSI2SS xmm1, xmm2, r/m32
VEX.LIG.F3.0F.W1 2A /r                  |VCVTSI2SS xmm1, xmm2, r/m64
CVTSS2SD—Convert
F3 0F 5A /r                             |CVTSS2SD xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 5A /r                 |VCVTSS2SD xmm1, xmm2,xmm3/m32
CVTSS2SI—Convert
F3 0F 2D /r                             |CVTSS2SI r32, xmm1/m32
F3 REX.W 0F 2D /r                       |CVTSS2SI r64, xmm1/m32
VEX.LIG.F3.0F.W0 2D /r 1                |VCVTSS2SI r32, xmm1/m32
VEX.LIG.F3.0F.W1 2D /r 1                |VCVTSS2SI r64, xmm1/m32
CVTTPD2DQ—Convert
66 0F E6 /r                             |CVTTPD2DQ xmm1, xmm2/m128
VEX.128.66.0F.WIG E6 /r                 |VCVTTPD2DQ xmm1, xmm2/m128
VEX.256.66.0F.WIG E6 /r                 |VCVTTPD2DQ xmm1, ymm2/m256
CVTTPD2PI—Convert
66 0F 2C /r                             |CVTTPD2PI mm, xmm/m128
CVTTPS2DQ—Convert
F3 0F 5B /r                             |CVTTPS2DQ xmm1, xmm2/m128
VEX.128.F3.0F.WIG 5B /r                 |VCVTTPS2DQ xmm1, xmm2/m128
VEX.256.F3.0F.WIG 5B /r                 |VCVTTPS2DQ ymm1, ymm2/m256
CVTTPS2PI—Convert
NP 0F 2C /r                             |CVTTPS2PI mm, xmm/m64
CVTTSD2SI—Convert
F2 0F 2C /r                             |CVTTSD2SI r32, xmm1/m64
F2 REX.W 0F 2C /r                       |CVTTSD2SI r64, xmm1/m64
VEX.LIG.F2.0F.W0 2C /r 1                |VCVTTSD2SI r32, xmm1/m64
VEX.LIG.F2.0F.W1 2C /r 1                |VCVTTSD2SI r64, xmm1/m64
CVTTSS2SI—Convert
F3 0F 2C /r                             |CVTTSS2SI r32, xmm1/m32
F3 REX.W 0F 2C /r                       |CVTTSS2SI r64, xmm1/m32
VEX.LIG.F3.0F.W0 2C /r 1                |VCVTTSS2SI r32, xmm1/m32
VEX.LIG.F3.0F.W1 2C /r 1                |VCVTTSS2SI r64, xmm1/m32
CWD/CDQ/CQO—Convert
99                                      |CWD
99                                      |CDQ
REX.W + 99                              |CQO
DEC—Decrement
FE /1                                   |DEC r/m8
REX + FE /1                             |DEC r/m8
FF /1                                   |DEC r/m16
FF /1                                   |DEC r/m32
REX.W + FF /1                           |DEC r/m64
DIV—Unsigned
F6 /6                                   |DIV r/m8
REX + F6 /6                             |DIV r/m8
F7 /6                                   |DIV r/m16
F7 /6                                   |DIV r/m32
REX.W + F7 /6                           |DIV r/m64
DIVPD—Divide
66 0F 5E /r                             |DIVPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 5E /r                 |VDIVPD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 5E /r                 |VDIVPD ymm1, ymm2, ymm3/m256
DIVPS—Divide
NP 0F 5E /r                             |DIVPS xmm1, xmm2/m128
VEX.128.0F.WIG 5E /r                    |VDIVPS xmm1, xmm2, xmm3/m128
VEX.256.0F.WIG 5E /r                    |VDIVPS ymm1, ymm2, ymm3/m256
DIVSD—Divide
F2 0F 5E /r                             |DIVSD xmm1, xmm2/m64
VEX.LIG.F2.0F.WIG 5E /r                 |VDIVSD xmm1, xmm2, xmm3/m64
DIVSS—Divide
F3 0F 5E /r                             |DIVSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 5E /r                 |VDIVSS xmm1, xmm2, xmm3/m32
DPPD—Dot
66 0F 3A 41 /r ib                       |DPPD xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 41 /r ib            |VDPPD xmm1,xmm2, xmm3/m128, imm8
DPPS—Dot
66 0F 3A 40 /r ib                       |DPPS xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 40 /r ib            |VDPPS xmm1,xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.WIG 40 /r ib            |VDPPS ymm1, ymm2, ymm3/m256, imm8
EMMS—Empty
NP 0F 77                                |EMMS
ENCODEKEY128—Encode
F3 0F 38 FA 11:rrr:bbb                  |ENCODEKEY128 r32, r32, <XMM0-2>,<XMM4-6>
ENCODEKEY256—Encode
F3 0F 38 FB 11:rrr:bbb                  |ENCODEKEY256 r32, r32 <XMM0-6>
ENDBR32—Terminate
F3 0F 1E FB                             |ENDBR32
ENDBR64—Terminate
F3 0F 1E FA                             |ENDBR64
ENTER—Make
C8 iw 00                                |ENTER imm16, 0
C8 iw 01                                |ENTER imm16,1
C8 iw ib                                |ENTER imm16, imm8
ENQCMD—Enqueue
F2 0F 38 F8 !(11):rrr:bbb               |ENQCMD r32/r64, m512
ENQCMDS—Enqueue
F3 0F 38 F8 !(11):rrr:bbb               |ENQCMDS r32/r64, m512
EXTRACTPS—Extract
66 0F 3A 17 /r ib                       |EXTRACTPS reg/m32, xmm1, imm8
VEX.128.66.0F3A.WIG 17 /r ib            |VEXTRACTPS reg/m32, xmm1, imm8
F2XM1—Compute
D9 F0                                   |F2XM1
FABS—Absolute
D9 E1                                   |FABS
FADD/FADDP/FIADD—Add
D8 /0                                   |FADD m32fp
DC /0                                   |FADD m64fp
D8 C0+i                                 |FADD ST(0), ST(i)
DC C0+i                                 |FADD ST(i), ST(0)
DE C0+i                                 |FADDP ST(i), ST(0)
DE C1                                   |FADDP
DA /0                                   |FIADD m32int
DE /0                                   |FIADD m16int
FBLD—Load
DF /4                                   |FBLD m80bcd
FBSTP—Store
DF /6                                   |FBSTP m80bcd
FCHS—Change
D9 E0                                   |FCHS
FCLEX/FNCLEX—Clear
9B DB E2                                |FCLEX
DB E2                                   |FNCLEX1
FCMOVcc—Floating-Point
DA C0+i                                 |FCMOVB ST(0), ST(i)
DA C8+i                                 |FCMOVE ST(0), ST(i)
DA D0+i                                 |FCMOVBE ST(0), ST(i)
DA D8+i                                 |FCMOVU ST(0), ST(i)
DB C0+i                                 |FCMOVNB ST(0), ST(i)
DB C8+i                                 |FCMOVNE ST(0), ST(i)
DB D0+i                                 |FCMOVNBE ST(0), ST(i)
DB D8+i                                 |FCMOVNU ST(0), ST(i)
FCOM/FCOMP/FCOMPP—Compare
D8 /2                                   |FCOM m32fp
DC /2                                   |FCOM m64fp
D8 D0+i                                 |FCOM ST(i)
D8 D1                                   |FCOM
D8 /3                                   |FCOMP m32fp
DC /3                                   |FCOMP m64fp
D8 D8+i                                 |FCOMP ST(i)
D8 D9                                   |FCOMP
DE D9                                   |FCOMPP
FCOS—Cosine
D9 FF                                   |FCOS
FDECSTP—Decrement
D9 F6                                   |FDECSTP
FDIV/FDIVP/FIDIV—Divide
D8 /6                                   |FDIV m32fp
DC /6                                   |FDIV m64fp
D8 F0+i                                 |FDIV ST(0), ST(i)
DC F8+i                                 |FDIV ST(i), ST(0)
DE F8+i                                 |FDIVP ST(i), ST(0)
DE F9                                   |FDIVP
DA /6                                   |FIDIV m32int
DE /6                                   |FIDIV m16int
FDIVR/FDIVRP/FIDIVR—Reverse
D8 /7                                   |FDIVR m32fp
DC /7                                   |FDIVR m64fp
D8 F8+i                                 |FDIVR ST(0), ST(i)
DC F0+i                                 |FDIVR ST(i), ST(0)
DE F0+i                                 |FDIVRP ST(i), ST(0)
DE F1                                   |FDIVRP
DA /7                                   |FIDIVR m32int
DE /7                                   |FIDIVR m16int
FFREE—Free
DD C0+i                                 |FFREE ST(i)
FICOM/FICOMP—Compare
DE /2                                   |FICOM m16int
DA /2                                   |FICOM m32int
DE /3                                   |FICOMP m16int
DA /3                                   |FICOMP m32int
FILD—Load
DF /0                                   |FILD m16int
DB /0                                   |FILD m32int
DF /5                                   |FILD m64int
FINCSTP—Increment
D9 F7                                   |FINCSTP
FINIT/FNINIT—Initialize
9B DB E3                                |FINIT
DB E3                                   |FNINIT1
FIST/FISTP—Store
DF /2                                   |FIST m16int
DB /2                                   |FIST m32int
DF /3                                   |FISTP m16int
DB /3                                   |FISTP m32int
DF /7                                   |FISTP m64int
FISTTP—Store
DF /1                                   |FISTTP m16int
DB /1                                   |FISTTP m32int
DD /1                                   |FISTTP m64int
FLD—Load
D9 /0                                   |FLD m32fp
DD /0                                   |FLD m64fp
DB /5                                   |FLD m80fp
D9 C0+i                                 |FLD ST(i)
FLD1/FLDL2T/FLDL2E/FLDPI/FLDLG2/FLDLN2/FLDZ—Load
D9 E8                                   |FLD1
D9 E9                                   |FLDL2T
D9 EA                                   |FLDL2E
D9 EB                                   |FLDPI
D9 EC                                   |FLDLG2
D9 ED                                   |FLDLN2
D9 EE                                   |FLDZ
FLDCW—Load
D9 /5                                   |FLDCW m2byte
FLDENV—Load
D9 /4                                   |FLDENV m14/28byte
FMUL/FMULP/FIMUL—Multiply
D8 /1                                   |FMUL m32fp
DC /1                                   |FMUL m64fp
D8 C8+i                                 |FMUL ST(0), ST(i)
DC C8+i                                 |FMUL ST(i), ST(0)
DE C8+i                                 |FMULP ST(i), ST(0)
DE C9                                   |FMULP
DA /1                                   |FIMUL m32int
DE /1                                   |FIMUL m16int
FNOP—No
D9 D0                                   |FNOP
FPATAN—Partial
D9 F3                                   |FPATAN
FPREM—Partial
D9 F8                                   |FPREM
FPREM1—Partial
D9 F5                                   |FPREM1
FPTAN—Partial
D9 F2                                   |FPTAN
FRNDINT—Round
D9 FC                                   |FRNDINT
FRSTOR—Restore
DD /4                                   |FRSTOR m94/108byte
FSAVE/FNSAVE—Store
9B DD /6                                |FSAVE m94/108byte
DD /6                                   |FNSAVE1 m94/108byte
FSCALE—Scale
D9 FD                                   |FSCALE
FSIN—Sine
D9 FE                                   |FSIN
FSINCOS—Sine
D9 FB                                   |FSINCOS
FSQRT—Square
D9 FA                                   |FSQRT
FST/FSTP—Store
D9 /2                                   |FST m32fp
DD /2                                   |FST m64fp
DD D0+i                                 |FST ST(i)
D9 /3                                   |FSTP m32fp
DD /3                                   |FSTP m64fp
DB /7                                   |FSTP m80fp
DD D8+i                                 |FSTP ST(i)
FSTCW/FNSTCW—Store
9B D9 /7                                |FSTCW m2byte
D9 /7                                   |FNSTCW1 m2byte
FSTENV/FNSTENV—Store
9B D9 /6                                |FSTENV m14/28byte
D9 /6                                   |FNSTENV1 m14/28byte
FSTSW/FNSTSW—Store
9B DD /7                                |FSTSW m2byte
9B DF E0                                |FSTSW AX
DD /7                                   |FNSTSW1 m2byte
DF E0                                   |FNSTSW1 AX
FSUB/FSUBP/FISUB—Subtract
D8 /4                                   |FSUB m32fp
DC /4                                   |FSUB m64fp
D8 E0+i                                 |FSUB ST(0), ST(i)
DC E8+i                                 |FSUB ST(i), ST(0)
DE E8+i                                 |FSUBP ST(i), ST(0)
DE E9                                   |FSUBP
DA /4                                   |FISUB m32int
DE /4                                   |FISUB m16int
FSUBR/FSUBRP/FISUBR—Reverse
D8 /5                                   |FSUBR m32fp
DC /5                                   |FSUBR m64fp
D8 E8+i                                 |FSUBR ST(0), ST(i)
DC E0+i                                 |FSUBR ST(i), ST(0)
DE E0+i                                 |FSUBRP ST(i), ST(0)
DE E1                                   |FSUBRP
DA /5                                   |FISUBR m32int
DE /5                                   |FISUBR m16int
FTST—TEST
D9 E4                                   |FTST
FUCOM/FUCOMP/FUCOMPP—Unordered
DD E0+i                                 |FUCOM ST(i)
DD E1                                   |FUCOM
DD E8+i                                 |FUCOMP ST(i)
DD E9                                   |FUCOMP
DA E9                                   |FUCOMPP
FXAM—Examine
D9 E5                                   |FXAM
FXCH—Exchange
D9 C8+i                                 |FXCH ST(i)
D9 C9                                   |FXCH
FXRSTOR—Restore
NP 0F AE /1                             |FXRSTOR m512byte
NP REX.W + 0F AE /1                     |FXRSTOR64 m512byte
FXSAVE—Save
NP 0F AE /0                             |FXSAVE m512byte
NP REX.W + 0F AE /0                     |FXSAVE64 m512byte
FXTRACT—Extract
D9 F4                                   |FXTRACT
FYL2X—Compute
D9 F1                                   |FYL2X
FYL2XP1—Compute
D9 F9                                   |FYL2XP1
GF2P8AFFINEINVQB—Galois
66 0F3A CF /r /ib                       |GF2P8AFFINEINVQB xmm1,xmm2/m128, imm8
VEX.128.66.0F3A.W1 CF /r /ib            |VGF2P8AFFINEINVQB xmm1, xmm2,xmm3/m128, imm8
VEX.256.66.0F3A.W1 CF /r /ib            |VGF2P8AFFINEINVQB ymm1, ymm2,ymm3/m256, imm8
GF2P8AFFINEQB—Galois
66 0F3A CE /r /ib                       |GF2P8AFFINEQB xmm1,xmm2/m128, imm8
VEX.128.66.0F3A.W1 CE /r /ib            |VGF2P8AFFINEQB xmm1, xmm2,xmm3/m128, imm8
VEX.256.66.0F3A.W1 CE /r /ib            |VGF2P8AFFINEQB ymm1, ymm2,ymm3/m256, imm8
GF2P8MULB—Galois
66 0F38 CF /r                           |GF2P8MULB xmm1, xmm2/m128
VEX.128.66.0F38.W0 CF /r                |VGF2P8MULB xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 CF /r                |VGF2P8MULB ymm1, ymm2,ymm3/m256
HADDPD—Packed
66 0F 7C /r                             |HADDPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 7C /r                 |VHADDPD xmm1,xmm2, xmm3/m128
VEX.256.66.0F.WIG 7C /r                 |VHADDPD ymm1, ymm2, ymm3/m256
HADDPS—Packed
F2 0F 7C /r                             |HADDPS xmm1, xmm2/m128
VEX.128.F2.0F.WIG 7C /r                 |VHADDPS xmm1, xmm2, xmm3/m128
VEX.256.F2.0F.WIG 7C /r                 |VHADDPS ymm1, ymm2, ymm3/m256
HLT—Halt
F4                                      |HLT
HRESET—History
F3 0F 3A F0 C0 /ib                      |HRESET imm8, <EAX>
HSUBPD—Packed
66 0F 7D /r                             |HSUBPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 7D /r                 |VHSUBPD xmm1,xmm2, xmm3/m128
VEX.256.66.0F.WIG 7D /r                 |VHSUBPD ymm1, ymm2, ymm3/m256
HSUBPS—Packed
F2 0F 7D /r                             |HSUBPS xmm1, xmm2/m128
VEX.128.F2.0F.WIG 7D /r                 |VHSUBPS xmm1, xmm2, xmm3/m128
VEX.256.F2.0F.WIG 7D /r                 |VHSUBPS ymm1, ymm2, ymm3/m256
IDIV—Signed
F6 /7                                   |IDIV r/m8
REX + F6 /7                             |IDIV r/m8
F7 /7                                   |IDIV r/m16
F7 /7                                   |IDIV r/m32
REX.W + F7 /7                           |IDIV r/m64
IMUL—Signed
F6 /5                                   |IMUL r/m8
F7 /5                                   |IMUL r/m16
F7 /5                                   |IMUL r/m32
REX.W + F7 /5                           |IMUL r/m64
0F AF /r                                |IMUL r16, r/m16
0F AF /r                                |IMUL r32, r/m32
REX.W + 0F AF /r                        |IMUL r64, r/m64
6B /r ib                                |IMUL r16, r/m16, imm8
6B /r ib                                |IMUL r32, r/m32, imm8
REX.W + 6B /r ib                        |IMUL r64, r/m64, imm8
69 /r iw                                |IMUL r16, r/m16, imm16
69 /r id                                |IMUL r32, r/m32, imm32
REX.W + 69 /r id                        |IMUL r64, r/m64, imm32
IN—Input
E4 ib                                   |IN AL, imm8
E5 ib                                   |IN AX, imm8
E5 ib                                   |IN EAX, imm8
EC                                      |IN AL,DX
ED                                      |IN AX,DX
ED                                      |IN EAX,DX
INC—Increment
FE /0                                   |INC r/m8
REX + FE /0                             |INC r/m8
FF /0                                   |INC r/m16
FF /0                                   |INC r/m32
REX.W + FF /0                           |INC r/m64
INCSSPD/INCSSPQ—Increment
F3 0F AE /05                            |INCSSPD r32
F3 REX.W 0F AE /05                      |INCSSPQ r64
INS/INSB/INSW/INSD—Input
6C                                      |INS m8, DX
6D                                      |INS m16, DX
6D                                      |INS m32, DX
6C                                      |INSB
6D                                      |INSW
6D                                      |INSD
INSERTPS—Insert
66 0F 3A 21 /r ib                       |INSERTPS xmm1, xmm2/m32, imm8
VEX.128.66.0F3A.WIG 21 /r ib            |VINSERTPS xmm1, xmm2, xmm3/m32,imm8
INVD—Invalidate
0F 08                                   |INVD
INVLPG—Invalidate
0F 01/7                                 |INVLPG m
INVPCID—Invalidate
66 0F 38 82 /r                          |INVPCID r64, m128
IRET/IRETD/IRETQ—Interrupt
CF                                      |IRET
CF                                      |IRETD
REX.W + CF                              |IRETQ
Jcc—Jump
77 cb                                   |JA rel8
73 cb                                   |JAE rel8
72 cb                                   |JB rel8
76 cb                                   |JBE rel8
72 cb                                   |JC rel8
E3 cb                                   |JECXZ rel8
E3 cb                                   |JRCXZ rel8
74 cb                                   |JE rel8
7F cb                                   |JG rel8
7D cb                                   |JGE rel8
7C cb                                   |JL rel8
7E cb                                   |JLE rel8
76 cb                                   |JNA rel8
72 cb                                   |JNAE rel8
73 cb                                   |JNB rel8
77 cb                                   |JNBE rel8
73 cb                                   |JNC rel8
75 cb                                   |JNE rel8
7E cb                                   |JNG rel8
7C cb                                   |JNGE rel8
7D cb                                   |JNL rel8
7F cb                                   |JNLE rel8
71 cb                                   |JNO rel8
7B cb                                   |JNP rel8
79 cb                                   |JNS rel8
75 cb                                   |JNZ rel8
70 cb                                   |JO rel8
7A cb                                   |JP rel8
7A cb                                   |JPE rel8
7B cb                                   |JPO rel8
78 cb                                   |JS rel8
74 cb                                   |JZ rel8
0F 87 cd                                |JA rel32
0F 83 cd                                |JAE rel32
Jcc—Jump
0F 82 cd                                |JB rel32
0F 86 cd                                |JBE rel32
0F 82 cd                                |JC rel32
0F 84 cd                                |JE rel32
0F 84 cd                                |JZ rel32
0F 8F cd                                |JG rel32
0F 8D cd                                |JGE rel32
0F 8C cd                                |JL rel32
0F 8E cd                                |JLE rel32
0F 86 cd                                |JNA rel32
0F 82 cd                                |JNAE rel32
0F 83 cd                                |JNB rel32
0F 87 cd                                |JNBE rel32
0F 83 cd                                |JNC rel32
Jcc—Jump
0F 85 cd                                |JNE rel32
0F 8E cd                                |JNG rel32
0F 8C cd                                |JNGE rel32
0F 8D cd                                |JNL rel32
0F 8F cd                                |JNLE rel32
0F 81 cd                                |JNO rel32
0F 8B cd                                |JNP rel32
0F 89 cd                                |JNS rel32
0F 85 cd                                |JNZ rel32
0F 80 cd                                |JO rel32
0F 8A cd                                |JP rel32
0F 8A cd                                |JPE rel32
0F 8B cd                                |JPO rel32
0F 88 cd                                |JS rel32
0F 84 cd                                |JZ rel32
JMP—Jump
EB cb                                   |JMP rel8
E9 cd                                   |JMP rel32
FF /4                                   |JMP r/m64
FF /5                                   |JMP m16:16
FF /5                                   |JMP m16:32
REX.W FF /5                             |JMP m16:64
LAR—Load
0F 02 /r                                |LAR r16, r16/m16
0F 02 /r                                |LAR reg, r32/m16
LDDQU—Load
F2 0F F0 /r                             |LDDQU xmm1, mem
VEX.128.F2.0F.WIG F0 /r                 |VLDDQU xmm1, m128
VEX.256.F2.0F.WIG F0 /r                 |VLDDQU ymm1, m256
LDMXCSR—Load
NP 0F AE /2                             |LDMXCSR m32
VEX.LZ.0F.WIG AE /2                     |VLDMXCSR m32
LDS/LES/LFS/LGS/LSS—Load
0F B2 /r                                |LSS r16,m16:16
0F B2 /r                                |LSS r32,m16:32
REX + 0F B2 /r                          |LSS r64,m16:64
0F B4 /r                                |LFS r16,m16:16
0F B4 /r                                |LFS r32,m16:32
REX + 0F B4 /r                          |LFS r64,m16:64
0F B5 /r                                |LGS r16,m16:16
0F B5 /r                                |LGS r32,m16:32
REX + 0F B5 /r                          |LGS r64,m16:64
LDTILECFG—Load
VEX.128.NP.0F38.W0 49 !(11):000:bbb     |LDTILECFG m512
LEA—Load
8D /r                                   |LEA r16,m
8D /r                                   |LEA r32,m
REX.W + 8D /r                           |LEA r64,m
LEAVE—High
C9                                      |LEAVE
C9                                      |LEAVE
LFENCE—Load
NP 0F AE E8                             |LFENCE
LGDT/LIDT—Load
0F 01 /2                                |LGDT m16&64
0F 01 /3                                |LIDT m16&64
LLDT—Load
0F 00 /2                                |LLDT r/m16
LMSW—Load
0F 01 /6                                |LMSW r/m16
LOADIWKEY—Load
F3 0F 38 DC 11:rrr:bbb                  |LOADIWKEY xmm1, xmm2, <EAX>, <XMM0>
LOCK—Assert
F0                                      |LOCK
LODS/LODSB/LODSW/LODSD/LODSQ—Load
AC                                      |LODS m8
AD                                      |LODS m16
AD                                      |LODS m32
REX.W + AD                              |LODS m64
AC                                      |LODSB
AD                                      |LODSW
AD                                      |LODSD
REX.W + AD                              |LODSQ
LOOP/LOOPcc—Loop
E2 cb                                   |LOOP rel8
E1 cb                                   |LOOPE rel8
E0 cb                                   |LOOPNE rel8
LSL—Load
0F 03 /r                                |LSL r16, r16/m16
0F 03 /r                                |LSL r32, r32/m16
REX.W + 0F 03 /r                        |LSL r64, r32/m16
LTR—Load
0F 00 /3                                |LTR r/m16
LZCNT—Count
F3 0F BD /r                             |LZCNT r16, r/m16
F3 0F BD /r                             |LZCNT r32, r/m32
F3 REX.W 0F BD /r                       |LZCNT r64, r/m64
MASKMOVDQU—Store
66 0F F7 /r                             |MASKMOVDQU xmm1, xmm2
VEX.128.66.0F.WIG F7 /r                 |VMASKMOVDQU xmm1, xmm2
MASKMOVQ—Store
NP 0F F7 /r                             |MASKMOVQ mm1, mm2
MAXPD—Maximum
66 0F 5F /r                             |MAXPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 5F /r                 |VMAXPD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 5F /r                 |VMAXPD ymm1, ymm2, ymm3/m256
MAXPS—Maximum
NP 0F 5F /r                             |MAXPS xmm1, xmm2/m128
VEX.128.0F.WIG 5F /r                    |VMAXPS xmm1, xmm2,xmm3/m128
VEX.256.0F.WIG 5F /r                    |VMAXPS ymm1, ymm2,ymm3/m256
MAXSD—Return
F2 0F 5F /r                             |MAXSD xmm1, xmm2/m64
VEX.LIG.F2.0F.WIG 5F /r                 |VMAXSD xmm1, xmm2, xmm3/m64
MAXSS—Return
F3 0F 5F /r                             |MAXSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 5F /r                 |VMAXSS xmm1, xmm2, xmm3/m32
MFENCE—Memory
NP 0F AE F0                             |MFENCE
MINPD—Minimum
66 0F 5D /r                             |MINPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 5D /r                 |VMINPD xmm1, xmm2,xmm3/m128
VEX.256.66.0F.WIG 5D /r                 |VMINPD ymm1, ymm2,ymm3/m256
MINPS—Minimum
NP 0F 5D /r                             |MINPS xmm1, xmm2/m128
VEX.128.0F.WIG 5D /r                    |VMINPS xmm1, xmm2,xmm3/m128
VEX.256.0F.WIG 5D /r                    |VMINPS ymm1, ymm2,ymm3/m256
MINSD—Return
F2 0F 5D /r                             |MINSD xmm1, xmm2/m64
VEX.LIG.F2.0F.WIG 5D /r                 |VMINSD xmm1, xmm2, xmm3/m64
MINSS—Return
F3 0F 5D /r                             |MINSS xmm1,xmm2/m32
VEX.LIG.F3.0F.WIG 5D /r                 |VMINSS xmm1,xmm2, xmm3/m32
MONITOR—Set
0F 01 C8                                |MONITOR
MOV—Move
88 /r                                   |MOV r/m8, r8
REX + 88 /r                             |MOV r/m8, r8
89 /r                                   |MOV r/m16, r16
89 /r                                   |MOV r/m32, r32
REX.W + 89 /r                           |MOV r/m64, r64
8A /r                                   |MOV r8, r/m8
REX + 8A /r                             |MOV r8, r/m8
8B /r                                   |MOV r16, r/m16
8B /r                                   |MOV r32, r/m32
REX.W + 8B /r                           |MOV r64, r/m64
8C /r                                   |MOV r/m16, Sreg
8C /r                                   |MOV r16/r32/m16, Sreg
REX.W + 8C /r                           |MOV r64/m16, Sreg
8E /r                                   |MOV Sreg, r/m16
REX.W + 8E /r                           |MOV Sreg, r/m64
A0                                      |MOV AL, moffs8
REX.W + A0                              |MOV AL, moffs8
A1                                      |MOV AX, moffs16
A1                                      |MOV EAX, moffs32
REX.W + A1                              |MOV RAX, moffs64
A2                                      |MOV moffs8, AL
REX.W + A2                              |MOV moffs8, AL
A3                                      |MOV moffs16, AX
A3                                      |MOV moffs32, EAX
REX.W + A3                              |MOV moffs64, RAX
B0+ rb ib                               |MOV r8, imm8
REX + B0+ rb ib                         |MOV r8, imm8
B8+ rw iw                               |MOV r16, imm16
B8+ rd id                               |MOV r32, imm32
REX.W + B8+ rd io                       |MOV r64, imm64
C6 /0 ib                                |MOV r/m8, imm8
REX + C6 /0 ib                          |MOV r/m8, imm8
C7 /0 iw                                |MOV r/m16, imm16
C7 /0 id                                |MOV r/m32, imm32
REX.W + C7 /0 id                        |MOV r/m64, imm32
MOV—Move
0F 20/r                                 |MOV r64, CR0–CR7
REX.R + 0F 20 /0                        |MOV r64, CR8
0F 22 /r                                |MOV CR0–CR7, r64
REX.R + 0F 22 /0                        |MOV CR8, r64
MOV—Move
0F 21/r                                 |MOV r64, DR0–DR7
0F 23 /r                                |MOV DR0–DR7, r64
MOVAPD—Move
66 0F 28 /r                             |MOVAPD xmm1, xmm2/m128
66 0F 29 /r                             |MOVAPD xmm2/m128, xmm1
VEX.128.66.0F.WIG 28 /r                 |VMOVAPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 29 /r                 |VMOVAPD xmm2/m128, xmm1
VEX.256.66.0F.WIG 28 /r                 |VMOVAPD ymm1, ymm2/m256
VEX.256.66.0F.WIG 29 /r                 |VMOVAPD ymm2/m256, ymm1
MOVAPS—Move
NP 0F 28 /r                             |MOVAPS xmm1, xmm2/m128
NP 0F 29 /r                             |MOVAPS xmm2/m128, xmm1
VEX.128.0F.WIG 28 /r                    |VMOVAPS xmm1, xmm2/m128
VEX.128.0F.WIG 29 /r                    |VMOVAPS xmm2/m128, xmm1
VEX.256.0F.WIG 28 /r                    |VMOVAPS ymm1, ymm2/m256
VEX.256.0F.WIG 29 /r                    |VMOVAPS ymm2/m256, ymm1
MOVBE—Move
0F 38 F0 /r                             |MOVBE r16, m16
0F 38 F0 /r                             |MOVBE r32, m32
REX.W + 0F 38 F0 /r                     |MOVBE r64, m64
0F 38 F1 /r                             |MOVBE m16, r16
0F 38 F1 /r                             |MOVBE m32, r32
REX.W + 0F 38 F1 /r                     |MOVBE m64, r64
MOVD/MOVQ—Move
NP 0F 6E /r                             |MOVD mm, r/m32
NP REX.W + 0F 6E /r                     |MOVQ mm, r/m64
NP 0F 7E /r                             |MOVD r/m32, mm
NP REX.W + 0F 7E /r                     |MOVQ r/m64, mm
66 0F 6E /r                             |MOVD xmm, r/m32
66 REX.W 0F 6E /r                       |MOVQ xmm, r/m64
66 0F 7E /r                             |MOVD r/m32, xmm
66 REX.W 0F 7E /r                       |MOVQ r/m64, xmm
VEX.128.66.0F.W0 6E /                   |VMOVD xmm1, r32/m32
VEX.128.66.0F.W1 6E /r                  |VMOVQ xmm1, r64/m64
VEX.128.66.0F.W0 7E /r                  |VMOVD r32/m32, xmm1
VEX.128.66.0F.W1 7E /r                  |VMOVQ r64/m64, xmm1
MOVDDUP—Replicate
F2 0F 12 /r                             |MOVDDUP xmm1, xmm2/m64
VEX.128.F2.0F.WIG 12 /r                 |VMOVDDUP xmm1, xmm2/m64
VEX.256.F2.0F.WIG 12 /r                 |VMOVDDUP ymm1, ymm2/m256
MOVDIRI—Move
NP 0F 38 F9 /r                          |MOVDIRI m32, r32
NP REX.W + 0F 38 F9 /r                  |MOVDIRI m64, r64
MOVDIR64B—Move
66 0F 38 F8 /r                          |MOVDIR64B r16/r32/r64, m512
MOVDQA,VMOVDQA32/64—Move
66 0F 6F /r                             |MOVDQA xmm1, xmm2/m128
66 0F 7F /r                             |MOVDQA xmm2/m128, xmm1
VEX.128.66.0F.WIG 6F /r                 |VMOVDQA xmm1, xmm2/m128
VEX.128.66.0F.WIG 7F /r                 |VMOVDQA xmm2/m128, xmm1
VEX.256.66.0F.WIG 6F /r                 |VMOVDQA ymm1, ymm2/m256
VEX.256.66.0F.WIG 7F /r                 |VMOVDQA ymm2/m256, ymm1
MOVDQU,VMOVDQU8/16/32/64—Move
F3 0F 6F /r                             |MOVDQU xmm1, xmm2/m128
F3 0F 7F /r                             |MOVDQU xmm2/m128, xmm1
VEX.128.F3.0F.WIG 6F /r                 |VMOVDQU xmm1, xmm2/m128
VEX.128.F3.0F.WIG 7F /r                 |VMOVDQU xmm2/m128, xmm1
VEX.256.F3.0F.WIG 6F /r                 |VMOVDQU ymm1, ymm2/m256
VEX.256.F3.0F.WIG 7F /r                 |VMOVDQU ymm2/m256, ymm1
MOVDQ2Q—Move
F2 0F D6 /r                             |MOVDQ2Q mm, xmm
MOVHLPS—Move
NP 0F 12 /r                             |MOVHLPS xmm1, xmm2
VEX.128.0F.WIG 12 /r                    |VMOVHLPS xmm1, xmm2, xmm3
MOVHPD—Move
66 0F 16 /r                             |MOVHPD xmm1, m64
VEX.128.66.0F.WIG 16 /r                 |VMOVHPD xmm2, xmm1, m64
66 0F 17 /r                             |MOVHPD m64, xmm1
VEX.128.66.0F.WIG 17 /r                 |VMOVHPD m64, xmm1
MOVHPS—Move
NP 0F 16 /r                             |MOVHPS xmm1, m64
VEX.128.0F.WIG 16 /r                    |VMOVHPS xmm2, xmm1, m64
NP 0F 17 /r                             |MOVHPS m64, xmm1
VEX.128.0F.WIG 17 /r                    |VMOVHPS m64, xmm1
MOVLHPS—Move
NP 0F 16 /r                             |MOVLHPS xmm1, xmm2
VEX.128.0F.WIG 16 /r                    |VMOVLHPS xmm1, xmm2, xmm3
MOVLPD—Move
66 0F 12 /r                             |MOVLPD xmm1, m64
VEX.128.66.0F.WIG 12 /r                 |VMOVLPD xmm2, xmm1, m64
66 0F 13/r                              |MOVLPD m64, xmm1
VEX.128.66.0F.WIG 13/r                  |VMOVLPD m64, xmm1
MOVLPS—Move
NP 0F 12 /r                             |MOVLPS xmm1, m64
VEX.128.0F.WIG 12 /r                    |VMOVLPS xmm2, xmm1, m64
0F 13/r                                 |MOVLPS m64, xmm1
VEX.128.0F.WIG 13/r                     |VMOVLPS m64, xmm1
MOVMSKPD—Extract
66 0F 50 /r                             |MOVMSKPD reg, xmm
VEX.128.66.0F.WIG 50 /r                 |VMOVMSKPD reg, xmm2
VEX.256.66.0F.WIG 50 /r                 |VMOVMSKPD reg, ymm2
MOVMSKPS—Extract
NP 0F 50 /r                             |MOVMSKPS reg, xmm
VEX.128.0F.WIG 50 /r                    |VMOVMSKPS reg, xmm2
VEX.256.0F.WIG 50 /r                    |VMOVMSKPS reg, ymm2
MOVNTDQA—Load
66 0F 38 2A /r                          |MOVNTDQA xmm1, m128
VEX.128.66.0F38.WIG 2A /r               |VMOVNTDQA xmm1, m128
VEX.256.66.0F38.WIG 2A /r               |VMOVNTDQA ymm1, m256
MOVNTDQ—Store
66 0F E7 /r                             |MOVNTDQ m128, xmm1
VEX.128.66.0F.WIG E7 /r                 |VMOVNTDQ m128, xmm1
VEX.256.66.0F.WIG E7 /r                 |VMOVNTDQ m256, ymm1
MOVNTI—Store
NP 0F C3 /r                             |MOVNTI m32, r32
NP REX.W + 0F C3 /r                     |MOVNTI m64, r64
MOVNTPD—Store
66 0F 2B /r                             |MOVNTPD m128, xmm1
VEX.128.66.0F.WIG 2B /r                 |VMOVNTPD m128, xmm1
VEX.256.66.0F.WIG 2B /r                 |VMOVNTPD m256, ymm1
MOVNTPS—Store
NP 0F 2B /r                             |MOVNTPS m128, xmm1
VEX.128.0F.WIG 2B /r                    |VMOVNTPS m128, xmm1
VEX.256.0F.WIG 2B /r                    |VMOVNTPS m256, ymm1
MOVNTQ—Store
NP 0F E7 /r                             |MOVNTQ m64, mm
MOVQ—Move
NP 0F 6F /r                             |MOVQ mm, mm/m64
NP 0F 7F /r                             |MOVQ mm/m64, mm
F3 0F 7E /r                             |MOVQ xmm1, xmm2/m64
VEX.128.F3.0F.WIG 7E /r                 |VMOVQ xmm1, xmm2/m64
66 0F D6 /r                             |MOVQ xmm2/m64, xmm1
VEX.128.66.0F.WIG D6 /r                 |VMOVQ xmm1/m64, xmm2
MOVQ2DQ—Move
F3 0F D6 /r                             |MOVQ2DQ xmm, mm
MOVS/MOVSB/MOVSW/MOVSD/MOVSQ—Move
A4                                      |MOVS m8, m8
A5                                      |MOVS m16, m16
A5                                      |MOVS m32, m32
REX.W + A5                              |MOVS m64, m64
A4                                      |MOVSB
A5                                      |MOVSW
A5                                      |MOVSD
REX.W + A5                              |MOVSQ
MOVSD—Move
F2 0F 10 /r                             |MOVSD xmm1, xmm2
F2 0F 10 /r                             |MOVSD xmm1, m64
F2 0F 11 /r                             |MOVSD xmm1/m64, xmm2
VEX.LIG.F2.0F.WIG 10 /r                 |VMOVSD xmm1, xmm2, xmm3
VEX.LIG.F2.0F.WIG 10 /r                 |VMOVSD xmm1, m64
VEX.LIG.F2.0F.WIG 11 /r                 |VMOVSD xmm1, xmm2, xmm3
VEX.LIG.F2.0F.WIG 11 /r                 |VMOVSD m64, xmm1
MOVSHDUP—Replicate
F3 0F 16 /r                             |MOVSHDUP xmm1, xmm2/m128
VEX.128.F3.0F.WIG 16 /r                 |VMOVSHDUP xmm1, xmm2/m128
VEX.256.F3.0F.WIG 16 /r                 |VMOVSHDUP ymm1, ymm2/m256
MOVSLDUP—Replicate
F3 0F 12 /r                             |MOVSLDUP xmm1, xmm2/m128
VEX.128.F3.0F.WIG 12 /r                 |VMOVSLDUP xmm1, xmm2/m128
VEX.256.F3.0F.WIG 12 /r                 |VMOVSLDUP ymm1, ymm2/m256
MOVSS—Move
F3 0F 10 /r                             |MOVSS xmm1, xmm2
F3 0F 10 /r                             |MOVSS xmm1, m32
VEX.LIG.F3.0F.WIG 10 /r                 |VMOVSS xmm1, xmm2, xmm3
VEX.LIG.F3.0F.WIG 10 /r                 |VMOVSS xmm1, m32
F3 0F 11 /r                             |MOVSS xmm2/m32, xmm1
VEX.LIG.F3.0F.WIG 11 /r                 |VMOVSS xmm1, xmm2, xmm3
VEX.LIG.F3.0F.WIG 11 /r                 |VMOVSS m32, xmm1
MOVSX/MOVSXD—Move
0F BE /r                                |MOVSX r16, r/m8
0F BE /r                                |MOVSX r32, r/m8
REX.W + 0F BE /r                        |MOVSX r64, r/m8
0F BF /r                                |MOVSX r32, r/m16
REX.W + 0F BF /r                        |MOVSX r64, r/m16
63 /r                                   |MOVSXD r16, r/m16
63 /r                                   |MOVSXD r32, r/m32
REX.W + 63 /r                           |MOVSXD r64, r/m32
MOVUPD—Move
66 0F 10 /r                             |MOVUPD xmm1, xmm2/m128
66 0F 11 /r                             |MOVUPD xmm2/m128, xmm1
VEX.128.66.0F.WIG 10 /r                 |VMOVUPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 11 /r                 |VMOVUPD xmm2/m128, xmm1
VEX.256.66.0F.WIG 10 /r                 |VMOVUPD ymm1, ymm2/m256
VEX.256.66.0F.WIG 11 /r                 |VMOVUPD ymm2/m256, ymm1
MOVUPS—Move
NP 0F 10 /r                             |MOVUPS xmm1, xmm2/m128
NP 0F 11 /r                             |MOVUPS xmm2/m128, xmm1
VEX.128.0F.WIG 10 /r                    |VMOVUPS xmm1, xmm2/m128
VEX.128.0F.WIG 11 /r                    |VMOVUPS xmm2/m128, xmm1
VEX.256.0F.WIG 10 /r                    |VMOVUPS ymm1, ymm2/m256
VEX.256.0F.WIG 11 /r                    |VMOVUPS ymm2/m256, ymm1
MOVZX—Move
0F B6 /r                                |MOVZX r16, r/m8
0F B6 /r                                |MOVZX r32, r/m8
REX.W + 0F B6 /r                        |MOVZX r64, r/m8
0F B7 /r                                |MOVZX r32, r/m16
REX.W + 0F B7 /r                        |MOVZX r64, r/m16
MPSADBW—Compute
66 0F 3A 42 /r ib                       |MPSADBW xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 42 /r ib            |VMPSADBW xmm1, xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.WIG 42 /r ib            |VMPSADBW ymm1, ymm2, ymm3/m256, imm8
MUL—Unsigned
F6 /4                                   |MUL r/m8
REX + F6 /4                             |MUL r/m8
F7 /4                                   |MUL r/m16
F7 /4                                   |MUL r/m32
REX.W + F7 /4                           |MUL r/m64
MULPD—Multiply
66 0F 59 /r                             |MULPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 59 /r                 |VMULPD xmm1,xmm2, xmm3/m128
VEX.256.66.0F.WIG 59 /r                 |VMULPD ymm1, ymm2, ymm3/m256
MULPS—Multiply
NP 0F 59 /r                             |MULPS xmm1, xmm2/m128
VEX.128.0F.WIG 59 /r                    |VMULPS xmm1,xmm2, xmm3/m128
VEX.256.0F.WIG 59 /r                    |VMULPS ymm1, ymm2, ymm3/m256
MULSD—Multiply
F2 0F 59 /r                             |MULSD xmm1,xmm2/m64
VEX.LIG.F2.0F.WIG 59 /r                 |VMULSD xmm1,xmm2, xmm3/m64
MULSS—Multiply
F3 0F 59 /r                             |MULSS xmm1,xmm2/m32
VEX.LIG.F3.0F.WIG 59 /r                 |VMULSS xmm1,xmm2, xmm3/m32
MULX—Unsigned
VEX.LZ.F2.0F38.W0 F6 /r                 |MULX r32a, r32b, r/m32
VEX.LZ.F2.0F38.W1 F6 /r                 |MULX r64a, r64b, r/m64
MWAIT—Monitor
0F 01 C9                                |MWAIT
NEG—Two's
F6 /3                                   |NEG r/m8
REX + F6 /3                             |NEG r/m8
F7 /3                                   |NEG r/m16
F7 /3                                   |NEG r/m32
REX.W + F7 /3                           |NEG r/m64
NOP—No
NP 90                                   |NOP
NP 0F 1F /0                             |NOP r/m16
NP 0F 1F /0                             |NOP r/m32
NOT—One's
F6 /2                                   |NOT r/m8
REX + F6 /2                             |NOT r/m8
F7 /2                                   |NOT r/m16
F7 /2                                   |NOT r/m32
REX.W + F7 /2                           |NOT r/m64
OR—Logical
0C ib                                   |OR AL, imm8
0D iw                                   |OR AX, imm16
0D id                                   |OR EAX, imm32
REX.W + 0D id                           |OR RAX, imm32
80 /1 ib                                |OR r/m8, imm8
REX + 80 /1 ib                          |OR r/m8, imm8
81 /1 iw                                |OR r/m16, imm16
81 /1 id                                |OR r/m32, imm32
REX.W + 81 /1 id                        |OR r/m64, imm32
83 /1 ib                                |OR r/m16, imm8
83 /1 ib                                |OR r/m32, imm8
REX.W + 83 /1 ib                        |OR r/m64, imm8
08 /r                                   |OR r/m8, r8
REX + 08 /r                             |OR r/m8, r8
09 /r                                   |OR r/m16, r16
09 /r                                   |OR r/m32, r32
REX.W + 09 /r                           |OR r/m64, r64
0A /r                                   |OR r8, r/m8
REX + 0A /r                             |OR r8, r/m8
0B /r                                   |OR r16, r/m16
0B /r                                   |OR r32, r/m32
REX.W + 0B /r                           |OR r64, r/m64
ORPD—Bitwise
66 0F 56/r                              |ORPD xmm1, xmm2/m128
VEX.128.66.0F 56 /r                     |VORPD xmm1,xmm2, xmm3/m128
VEX.256.66.0F 56 /r                     |VORPD ymm1, ymm2, ymm3/m256
ORPS—Bitwise
NP 0F 56 /r                             |ORPS xmm1, xmm2/m128
VEX.128.0F 56 /r                        |VORPS xmm1,xmm2, xmm3/m128
VEX.256.0F 56 /r                        |VORPS ymm1, ymm2, ymm3/m256
OUT—Output
E6 ib                                   |OUT imm8, AL
E7 ib                                   |OUT imm8, AX
E7 ib                                   |OUT imm8, EAX
EE                                      |OUT DX, AL
EF                                      |OUT DX, AX
EF                                      |OUT DX, EAX
OUTS/OUTSB/OUTSW/OUTSD—Output
6E                                      |OUTS DX, m8
6F                                      |OUTS DX, m16
6F                                      |OUTS DX, m32
6E                                      |OUTSB
6F                                      |OUTSW
6F                                      |OUTSD
PABSB/PABSW/PABSD/PABSQ—Packed
NP 0F 38 1C /r1                         |PABSB mm1, mm2/m64
66 0F 38 1C /r                          |PABSB xmm1, xmm2/m128
NP 0F 38 1D /r1                         |PABSW mm1, mm2/m64
66 0F 38 1D /r                          |PABSW xmm1, xmm2/m128
NP 0F 38 1E /r1                         |PABSD mm1, mm2/m64
66 0F 38 1E /r                          |PABSD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 1C /r               |VPABSB xmm1, xmm2/m128
VEX.128.66.0F38.WIG 1D /r               |VPABSW xmm1, xmm2/m128
VEX.128.66.0F38.WIG 1E /r               |VPABSD xmm1, xmm2/m128
VEX.256.66.0F38.WIG 1C /r               |VPABSB ymm1, ymm2/m256
VEX.256.66.0F38.WIG 1D /r               |VPABSW ymm1, ymm2/m256
VEX.256.66.0F38.WIG 1E /r               |VPABSD ymm1, ymm2/m256
PACKSSWB/PACKSSDW—Pack
NP 0F 63 /r1                            |PACKSSWB mm1, mm2/m64
66 0F 63 /r                             |PACKSSWB xmm1, xmm2/m128
NP 0F 6B /r1                            |PACKSSDW mm1, mm2/m64
66 0F 6B /r                             |PACKSSDW xmm1, xmm2/m128
VEX.128.66.0F.WIG 63 /r                 |VPACKSSWB xmm1,xmm2, xmm3/m128
VEX.128.66.0F.WIG 6B /r                 |VPACKSSDW xmm1,xmm2, xmm3/m128
VEX.256.66.0F.WIG 63 /r                 |VPACKSSWB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 6B /r                 |VPACKSSDW ymm1, ymm2, ymm3/m256
PACKUSDW—Pack
66 0F 38 2B /r                          |PACKUSDW xmm1, xmm2/m128
VEX.128.66.0F38 2B /r                   |VPACKUSDW xmm1,xmm2,xmm3/m128
VEX.256.66.0F38 2B /r                   |VPACKUSDW ymm1, ymm2,ymm3/m256
PACKUSWB—Pack
NP 0F 67 /r1                            |PACKUSWB mm, mm/m64
66 0F 67 /r                             |PACKUSWB xmm1, xmm2/m128
VEX.128.66.0F.WIG 67 /r                 |VPACKUSWB xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 67 /r                 |VPACKUSWB ymm1, ymm2, ymm3/m256
PADDB/PADDW/PADDD/PADDQ—Add
NP 0F FC /r1                            |PADDB mm, mm/m64
NP 0F FD /r1                            |PADDW mm, mm/m64
NP 0F FE /r1                            |PADDD mm, mm/m64
NP 0F D4 /r1                            |PADDQ mm, mm/m64
66 0F FC /r                             |PADDB xmm1, xmm2/m128
66 0F FD /r                             |PADDW xmm1, xmm2/m128
66 0F FE /r                             |PADDD xmm1, xmm2/m128
66 0F D4 /r                             |PADDQ xmm1, xmm2/m128
VEX.128.66.0F.WIG FC /r                 |VPADDB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG FD /r                 |VPADDW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG FE /r                 |VPADDD xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG D4 /r                 |VPADDQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG FC /r                 |VPADDB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG FD /r                 |VPADDW ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG FE /r                 |VPADDD ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG D4 /r                 |VPADDQ ymm1, ymm2, ymm3/m256
PADDSB/PADDSW—Add
NP 0F EC /r1                            |PADDSB mm, mm/m64
66 0F EC /r                             |PADDSB xmm1, xmm2/m128
NP 0F ED /r1                            |PADDSW mm, mm/m64
66 0F ED /r                             |PADDSW xmm1, xmm2/m128
VEX.128.66.0F.WIG EC /r                 |VPADDSB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG ED /r                 |VPADDSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG EC /r                 |VPADDSB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG ED /r                 |VPADDSW ymm1, ymm2, ymm3/m256
PADDUSB/PADDUSW—Add
NP 0F DC /r1                            |PADDUSB mm, mm/m64
66 0F DC /r                             |PADDUSB xmm1, xmm2/m128
NP 0F DD /r1                            |PADDUSW mm, mm/m64
66 0F DD /r                             |PADDUSW xmm1, xmm2/m128
VEX.128.660F.WIG DC /r                  |VPADDUSB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG DD /r                 |VPADDUSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG DC /r                 |VPADDUSB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG DD /r                 |VPADDUSW ymm1, ymm2, ymm3/m256
PALIGNR—Packed
NP 0F 3A 0F /r ib1                      |PALIGNR mm1, mm2/m64, imm8
66 0F 3A 0F /r ib                       |PALIGNR xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 0F /r ib            |VPALIGNR xmm1, xmm2, xmm3/m128,imm8
VEX.256.66.0F3A.WIG 0F /r ib            |VPALIGNR ymm1, ymm2, ymm3/m256,imm8
PAND—Logical
NP 0F DB /r1                            |PAND mm, mm/m64
66 0F DB /r                             |PAND xmm1, xmm2/m128
VEX.128.66.0F.WIG DB /r                 |VPAND xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG DB /r                 |VPAND ymm1, ymm2, ymm3/.m256
PANDN—Logical
NP 0F DF /r1                            |PANDN mm, mm/m64
66 0F DF /r                             |PANDN xmm1, xmm2/m128
VEX.128.66.0F.WIG DF /r                 |VPANDN xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG DF /r                 |VPANDN ymm1, ymm2, ymm3/m256
PAUSE—Spin
F3 90                                   |PAUSE
PAVGB/PAVGW—Average
NP 0F E0 /r1                            |PAVGB mm1, mm2/m64
66 0F E0, /r                            |PAVGB xmm1, xmm2/m128
NP 0F E3 /r1                            |PAVGW mm1, mm2/m64
66 0F E3 /r                             |PAVGW xmm1, xmm2/m128
VEX.128.66.0F.WIG E0 /r                 |VPAVGB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG E3 /r                 |VPAVGW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG E0 /r                 |VPAVGB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG E3 /r                 |VPAVGW ymm1, ymm2, ymm3/m256
PBLENDVB—Variable
66 0F 38 10 /r                          |PBLENDVB xmm1, xmm2/m128, <XMM0>
VEX.128.66.0F3A.W0 4C /r /is4           |VPBLENDVB xmm1, xmm2, xmm3/m128, xmm4
VEX.256.66.0F3A.W0 4C /r /is4           |VPBLENDVB ymm1, ymm2, ymm3/m256, ymm4
PBLENDW—Blend
66 0F 3A 0E /r ib                       |PBLENDW xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 0E /r ib            |VPBLENDW xmm1, xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.WIG 0E /r ib            |VPBLENDW ymm1, ymm2, ymm3/m256, imm8
PCLMULQDQ—Carry-Less
66 0F 3A 44 /r ib                       |PCLMULQDQ xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 44 /r ib            |VPCLMULQDQ xmm1, xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.WIG 44 /r /ib           |VPCLMULQDQ ymm1, ymm2, ymm3/m256, imm8
PCMPEQB/PCMPEQW/PCMPEQD—
NP 0F 74 /r1                            |PCMPEQB mm, mm/m64
66 0F 74 /r                             |PCMPEQB xmm1, xmm2/m128
NP 0F 75 /r1                            |PCMPEQW mm, mm/m64
66 0F 75 /r                             |PCMPEQW xmm1, xmm2/m128
NP 0F 76 /r1                            |PCMPEQD mm, mm/m64
66 0F 76 /r                             |PCMPEQD xmm1, xmm2/m128
VEX.128.66.0F.WIG 74 /r                 |VPCMPEQB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 75 /r                 |VPCMPEQW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 76 /r                 |VPCMPEQD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 74 /r                 |VPCMPEQB ymm1, ymm2, ymm3 /m256
VEX.256.66.0F.WIG 75 /r                 |VPCMPEQW ymm1, ymm2, ymm3 /m256
VEX.256.66.0F.WIG 76 /r                 |VPCMPEQD ymm1, ymm2, ymm3 /m256
PCMPEQQ—Compare
66 0F 38 29 /r                          |PCMPEQQ xmm1, xmm2/m128
VEX.128.66.0F38.WIG 29 /r               |VPCMPEQQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 29 /r               |VPCMPEQQ ymm1, ymm2, ymm3 /m256
PCMPESTRI—Packed
66 0F 3A 61 /r imm8                     |PCMPESTRI xmm1, xmm2/m128, imm8
VEX.128.66.0F3A 61 /r ib                |VPCMPESTRI xmm1, xmm2/m128, imm8
PCMPESTRM—Packed
66 0F 3A 60 /r imm8                     |PCMPESTRM xmm1, xmm2/m128, imm8
VEX.128.66.0F3A 60 /r ib                |VPCMPESTRM xmm1, xmm2/m128, imm8
PCMPGTB/PCMPGTW/PCMPGTD—Compare
NP 0F 64 /r1                            |PCMPGTB mm, mm/m64
66 0F 64 /r                             |PCMPGTB xmm1, xmm2/m128
NP 0F 65 /r1                            |PCMPGTW mm, mm/m64
66 0F 65 /r                             |PCMPGTW xmm1, xmm2/m128
NP 0F 66 /r1                            |PCMPGTD mm, mm/m64
66 0F 66 /r                             |PCMPGTD xmm1, xmm2/m128
VEX.128.66.0F.WIG 64 /r                 |VPCMPGTB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 65 /r                 |VPCMPGTW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 66 /r                 |VPCMPGTD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 64 /r                 |VPCMPGTB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 65 /r                 |VPCMPGTW ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 66 /r                 |VPCMPGTD ymm1, ymm2, ymm3/m256
PCMPGTQ—Compare
66 0F 38 37 /r                          |PCMPGTQ xmm1,xmm2/m128
VEX.128.66.0F38.WIG 37 /r               |VPCMPGTQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 37 /r               |VPCMPGTQ ymm1, ymm2, ymm3/m256
PCMPISTRI—Packed
66 0F 3A 63 /r imm8                     |PCMPISTRI xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 63 /r ib            |VPCMPISTRI xmm1, xmm2/m128, imm8
PCMPISTRM—Packed
66 0F 3A 62 /r imm8                     |PCMPISTRM xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 62 /r ib            |VPCMPISTRM xmm1, xmm2/m128, imm8
PCONFIG—Platform
NP 0F 01 C5                             |PCONFIG
PDEP—Parallel
VEX.LZ.F2.0F38.W0 F5 /r                 |PDEP r32a, r32b, r/m32
VEX.LZ.F2.0F38.W1 F5 /r                 |PDEP r64a, r64b, r/m64
PEXT—Parallel
VEX.LZ.F3.0F38.W0 F5 /r                 |PEXT r32a, r32b, r/m32
VEX.LZ.F3.0F38.W1 F5 /r                 |PEXT r64a, r64b, r/m64
PEXTRB/PEXTRD/PEXTRQ—Extract
66 0F 3A 14 /r ib                       |PEXTRB reg/m8, xmm2, imm8
66 0F 3A 16 /r ib                       |PEXTRD r/m32, xmm2, imm8
66 REX.W 0F 3A 16 /r ib                 |PEXTRQ r/m64, xmm2, imm8
VEX.128.66.0F3A.W0 14 /r ib             |VPEXTRB reg/m8, xmm2, imm8
VEX.128.66.0F3A.W0 16 /r ib             |VPEXTRD r32/m32, xmm2, imm8
VEX.128.66.0F3A.W1 16 /r ib             |VPEXTRQ r64/m64, xmm2, imm8
PEXTRW—Extract
NP 0F C5 /r ib1                         |PEXTRW reg, mm, imm8
66 0F C5 /r ib                          |PEXTRW reg, xmm, imm8
66 0F 3A 15 /r ib                       |PEXTRW reg/m16, xmm, imm8
VEX.128.66.0F.W0 C5 /r ib               |VPEXTRW reg, xmm1, imm8
VEX.128.66.0F3A.W0 15 /r ib             |VPEXTRW reg/m16, xmm2, imm8
PHADDW/PHADDD—Packed
NP 0F 38 01 /r1                         |PHADDW mm1, mm2/m64
66 0F 38 01 /r                          |PHADDW xmm1, xmm2/m128
NP 0F 38 02 /r                          |PHADDD mm1, mm2/m64
66 0F 38 02 /r                          |PHADDD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 01 /r               |VPHADDW xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.WIG 02 /r               |VPHADDD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 01 /r               |VPHADDW ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.WIG 02 /r               |VPHADDD ymm1, ymm2, ymm3/m256
PHADDSW—Packed
NP 0F 38 03 /r1                         |PHADDSW mm1, mm2/m64
66 0F 38 03 /r                          |PHADDSW xmm1, xmm2/m128
VEX.128.66.0F38.WIG 03 /r               |VPHADDSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 03 /r               |VPHADDSW ymm1, ymm2, ymm3/m256
PHMINPOSUW—Packed
66 0F 38 41 /r                          |PHMINPOSUW xmm1, xmm2/m128
VEX.128.66.0F38.WIG 41 /r               |VPHMINPOSUW xmm1, xmm2/m128
PHSUBW/PHSUBD—Packed
NP 0F 38 05 /r1                         |PHSUBW mm1, mm2/m64
66 0F 38 05 /r                          |PHSUBW xmm1, xmm2/m128
NP 0F 38 06 /r                          |PHSUBD mm1, mm2/m64
66 0F 38 06 /r                          |PHSUBD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 05 /r               |VPHSUBW xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.WIG 06 /r               |VPHSUBD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 05 /r               |VPHSUBW ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.WIG 06 /r               |VPHSUBD ymm1, ymm2, ymm3/m256
PHSUBSW—Packed
NP 0F 38 07 /r1                         |PHSUBSW mm1, mm2/m64
66 0F 38 07 /r                          |PHSUBSW xmm1, xmm2/m128
VEX.128.66.0F38.WIG 07 /r               |VPHSUBSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 07 /r               |VPHSUBSW ymm1, ymm2, ymm3/m256
PINSRB/PINSRD/PINSRQ—Insert
66 0F 3A 20 /r ib                       |PINSRB xmm1, r32/m8, imm8
66 0F 3A 22 /r ib                       |PINSRD xmm1, r/m32, imm8
66 REX.W 0F 3A 22 /r ib                 |PINSRQ xmm1, r/m64, imm8
VEX.128.66.0F3A.W0 20 /r ib             |VPINSRB xmm1, xmm2, r32/m8, imm8
VEX.128.66.0F3A.W0 22 /r ib             |VPINSRD xmm1, xmm2, r/m32, imm8
VEX.128.66.0F3A.W1 22 /r ib             |VPINSRQ xmm1, xmm2, r/m64, imm8
PINSRW—Insert
NP 0F C4 /r ib1                         |PINSRW mm, r32/m16, imm8
66 0F C4 /r ib                          |PINSRW xmm, r32/m16, imm8
VEX.128.66.0F.W0 C4 /r ib               |VPINSRW xmm1, xmm2, r32/m16, imm8
PMADDUBSW—Multiply
NP 0F 38 04 /r1                         |PMADDUBSW mm1, mm2/m64
66 0F 38 04 /r                          |PMADDUBSW xmm1, xmm2/m128
VEX.128.66.0F38.WIG 04 /r               |VPMADDUBSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 04 /r               |VPMADDUBSW ymm1, ymm2, ymm3/m256
PMADDWD—Multiply
NP 0F F5 /r1                            |PMADDWD mm, mm/m64
66 0F F5 /r                             |PMADDWD xmm1, xmm2/m128
VEX.128.66.0F.WIG F5 /r                 |VPMADDWD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG F5 /r                 |VPMADDWD ymm1, ymm2, ymm3/m256
PMAXSB/PMAXSW/PMAXSD/PMAXSQ—Maximum
NP 0F EE /r1                            |PMAXSW mm1, mm2/m64
66 0F 38 3C /r                          |PMAXSB xmm1, xmm2/m128
66 0F EE /r                             |PMAXSW xmm1, xmm2/m128
66 0F 38 3D /r                          |PMAXSD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 3C /r               |VPMAXSB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG EE /r                 |VPMAXSW xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.WIG 3D /r               |VPMAXSD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 3C /r               |VPMAXSB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG EE /r                 |VPMAXSW ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.WIG 3D /r               |VPMAXSD ymm1, ymm2, ymm3/m256
PMAXUB/PMAXUW—Maximum
NP 0F DE /r1                            |PMAXUB mm1, mm2/m64
66 0F DE /r                             |PMAXUB xmm1, xmm2/m128
66 0F 38 3E/r                           |PMAXUW xmm1, xmm2/m128
VEX.128.66.0F DE /r                     |VPMAXUB xmm1, xmm2, xmm3/m128
VEX.128.66.0F38 3E/r                    |VPMAXUW xmm1, xmm2, xmm3/m128
VEX.256.66.0F DE /r                     |VPMAXUB ymm1, ymm2, ymm3/m256
VEX.256.66.0F38 3E/r                    |VPMAXUW ymm1, ymm2, ymm3/m256
PMAXUD/PMAXUQ—Maximum
66 0F 38 3F /r                          |PMAXUD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 3F /r               |VPMAXUD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 3F /r               |VPMAXUD ymm1, ymm2, ymm3/m256
PMINSB/PMINSW—Minimum
NP 0F EA /r1                            |PMINSW mm1, mm2/m64
66 0F 38 38 /r                          |PMINSB xmm1, xmm2/m128
66 0F EA /r                             |PMINSW xmm1, xmm2/m128
VEX.128.66.0F38 38 /r                   |VPMINSB xmm1, xmm2, xmm3/m128
VEX.128.66.0F EA /r                     |VPMINSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F38 38 /r                   |VPMINSB ymm1, ymm2, ymm3/m256
VEX.256.66.0F EA /r                     |VPMINSW ymm1, ymm2, ymm3/m256
PMINSD/PMINSQ—Minimum
66 0F 38 39 /r                          |PMINSD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 39 /r               |VPMINSD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 39 /r               |VPMINSD ymm1, ymm2, ymm3/m256
PMINUB/PMINUW—Minimum
NP 0F DA /r1                            |PMINUB mm1, mm2/m64
66 0F DA /r                             |PMINUB xmm1, xmm2/m128
66 0F 38 3A/r                           |PMINUW xmm1, xmm2/m128
VEX.128.66.0F DA /r                     |VPMINUB xmm1, xmm2, xmm3/m128
VEX.128.66.0F38 3A/r                    |VPMINUW xmm1, xmm2, xmm3/m128
VEX.256.66.0F DA /r                     |VPMINUB ymm1, ymm2, ymm3/m256
VEX.256.66.0F38 3A/r                    |VPMINUW ymm1, ymm2, ymm3/m256
PMINUD/PMINUQ—Minimum
66 0F 38 3B /r                          |PMINUD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 3B /r               |VPMINUD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.WIG 3B /r               |VPMINUD ymm1, ymm2,ymm3/m256
PMOVMSKB—Move
NP 0F D7 /r1                            |PMOVMSKB reg, mm
66 0F D7 /r                             |PMOVMSKB reg, xmm
VEX.128.66.0F.WIG D7 /r                 |VPMOVMSKB reg, xmm1
VEX.256.66.0F.WIG D7 /r                 |VPMOVMSKB reg, ymm1
PMOVSX—Packed
66 0f 38 20 /r                          |PMOVSXBW xmm1, xmm2/m64
66 0f 38 21 /r                          |PMOVSXBD xmm1, xmm2/m32
66 0f 38 22 /r                          |PMOVSXBQ xmm1, xmm2/m16
66 0f 38 23/r                           |PMOVSXWD xmm1, xmm2/m64
66 0f 38 24 /r                          |PMOVSXWQ xmm1, xmm2/m32
66 0f 38 25 /r                          |PMOVSXDQ xmm1, xmm2/m64
VEX.128.66.0F38.WIG 20 /r               |VPMOVSXBW xmm1, xmm2/m64
VEX.128.66.0F38.WIG 21 /r               |VPMOVSXBD xmm1, xmm2/m32
VEX.128.66.0F38.WIG 22 /r               |VPMOVSXBQ xmm1, xmm2/m16
VEX.128.66.0F38.WIG 23 /r               |VPMOVSXWD xmm1, xmm2/m64
VEX.128.66.0F38.WIG 24 /r               |VPMOVSXWQ xmm1, xmm2/m32
VEX.128.66.0F38.WIG 25 /r               |VPMOVSXDQ xmm1, xmm2/m64
VEX.256.66.0F38.WIG 20 /r               |VPMOVSXBW ymm1, xmm2/m128
VEX.256.66.0F38.WIG 21 /r               |VPMOVSXBD ymm1, xmm2/m64
VEX.256.66.0F38.WIG 22 /r               |VPMOVSXBQ ymm1, xmm2/m32
VEX.256.66.0F38.WIG 23 /r               |VPMOVSXWD ymm1, xmm2/m128
VEX.256.66.0F38.WIG 24 /r               |VPMOVSXWQ ymm1, xmm2/m64
VEX.256.66.0F38.WIG 25 /r               |VPMOVSXDQ ymm1, xmm2/m128
PMOVZX—Packed
66 0f 38 30 /r                          |PMOVZXBW xmm1, xmm2/m64
66 0f 38 31 /r                          |PMOVZXBD xmm1, xmm2/m32
66 0f 38 32 /r                          |PMOVZXBQ xmm1, xmm2/m16
66 0f 38 33 /r                          |PMOVZXWD xmm1, xmm2/m64
66 0f 38 34 /r                          |PMOVZXWQ xmm1, xmm2/m32
66 0f 38 35 /r                          |PMOVZXDQ xmm1, xmm2/m64
VEX.128.66.0F38.WIG 30 /r               |VPMOVZXBW xmm1, xmm2/m64
VEX.128.66.0F38.WIG 31 /r               |VPMOVZXBD xmm1, xmm2/m32
VEX.128.66.0F38.WIG 32 /r               |VPMOVZXBQ xmm1, xmm2/m16
VEX.128.66.0F38.WIG 33 /r               |VPMOVZXWD xmm1, xmm2/m64
VEX.128.66.0F38.WIG 34 /r               |VPMOVZXWQ xmm1, xmm2/m32
VEX.128.66.0F 38.WIG 35 /r              |VPMOVZXDQ xmm1, xmm2/m64
VEX.256.66.0F38.WIG 30 /r               |VPMOVZXBW ymm1, xmm2/m128
VEX.256.66.0F38.WIG 31 /r               |VPMOVZXBD ymm1, xmm2/m64
VEX.256.66.0F38.WIG 32 /r               |VPMOVZXBQ ymm1, xmm2/m32
VEX.256.66.0F38.WIG 33 /r               |VPMOVZXWD ymm1, xmm2/m128
PMOVZX—Packed
VEX.256.66.0F38.WIG 34 /r               |VPMOVZXWQ ymm1, xmm2/m64
VEX.256.66.0F38.WIG 35 /r               |VPMOVZXDQ ymm1, xmm2/m128
PMULDQ—Multiply
66 0F 38 28 /r                          |PMULDQ xmm1, xmm2/m128
VEX.128.66.0F38.WIG 28 /r               |VPMULDQ xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.WIG 28 /r               |VPMULDQ ymm1, ymm2,ymm3/m256
PMULHRSW—Packed
NP 0F 38 0B /r1                         |PMULHRSW mm1, mm2/m64
66 0F 38 0B /r                          |PMULHRSW xmm1, xmm2/m128
VEX.128.66.0F38.WIG 0B /r               |VPMULHRSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 0B /r               |VPMULHRSW ymm1, ymm2, ymm3/m256
PMULHUW—Multiply
NP 0F E4 /r1                            |PMULHUW mm1, mm2/m64
66 0F E4 /r                             |PMULHUW xmm1, xmm2/m128
VEX.128.66.0F.WIG E4 /r                 |VPMULHUW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG E4 /r                 |VPMULHUW ymm1, ymm2, ymm3/m256
PMULHW—Multiply
NP 0F E5 /r1                            |PMULHW mm, mm/m64
66 0F E5 /r                             |PMULHW xmm1, xmm2/m128
VEX.128.66.0F.WIG E5 /r                 |VPMULHW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG E5 /r                 |VPMULHW ymm1, ymm2, ymm3/m256
PMULLD/PMULLQ—Multiply
66 0F 38 40 /r                          |PMULLD xmm1, xmm2/m128
VEX.128.66.0F38.WIG 40 /r               |VPMULLD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.WIG 40 /r               |VPMULLD ymm1, ymm2,ymm3/m256
PMULLW—Multiply
NP 0F D5 /r1                            |PMULLW mm, mm/m64
66 0F D5 /r                             |PMULLW xmm1, xmm2/m128
VEX.128.66.0F.WIG D5 /r                 |VPMULLW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG D5 /r                 |VPMULLW ymm1, ymm2, ymm3/m256
PMULUDQ—Multiply
NP 0F F4 /r1                            |PMULUDQ mm1, mm2/m64
66 0F F4 /r                             |PMULUDQ xmm1, xmm2/m128
VEX.128.66.0F.WIG F4 /r                 |VPMULUDQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG F4 /r                 |VPMULUDQ ymm1, ymm2, ymm3/m256
POP—Pop
8F /0                                   |POP r/m16
8F /0                                   |POP r/m64
58+ rw                                  |POP r16
58+ rd                                  |POP r64
0F A1                                   |POP FS
0F A1                                   |POP FS
0F A9                                   |POP GS
0F A9                                   |POP GS
POPCNT—Return
F3 0F B8 /r                             |POPCNT r16, r/m16
F3 0F B8 /r                             |POPCNT r32, r/m32
F3 REX.W 0F B8 /r                       |POPCNT r64, r/m64
POPF/POPFD/POPFQ—Pop
9D                                      |POPF
9D                                      |POPFQ
POR—Bitwise
NP 0F EB /r1                            |POR mm, mm/m64
66 0F EB /r                             |POR xmm1, xmm2/m128
VEX.128.66.0F.WIG EB /r                 |VPOR xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG EB /r                 |VPOR ymm1, ymm2, ymm3/m256
PREFETCHh—Prefetch
0F 18 /1                                |PREFETCHT0 m8
0F 18 /2                                |PREFETCHT1 m8
0F 18 /3                                |PREFETCHT2 m8
0F 18 /0                                |PREFETCHNTA m8
PREFETCHW—Prefetch
0F 0D /1                                |PREFETCHW m8
PSADBW—Compute
NP 0F F6 /r1                            |PSADBW mm1, mm2/m64
66 0F F6 /r                             |PSADBW xmm1, xmm2/m128
VEX.128.66.0F.WIG F6 /r                 |VPSADBW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG F6 /r                 |VPSADBW ymm1, ymm2, ymm3/m256
PSHUFB—Packed
NP 0F 38 00 /r1                         |PSHUFB mm1, mm2/m64
66 0F 38 00 /r                          |PSHUFB xmm1, xmm2/m128
VEX.128.66.0F38.WIG 00 /r               |VPSHUFB xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 00 /r               |VPSHUFB ymm1, ymm2, ymm3/m256
PSHUFD—Shuffle
66 0F 70 /r ib                          |PSHUFD xmm1, xmm2/m128, imm8
VEX.128.66.0F.WIG 70 /r ib              |VPSHUFD xmm1, xmm2/m128, imm8
VEX.256.66.0F.WIG 70 /r ib              |VPSHUFD ymm1, ymm2/m256, imm8
PSHUFHW—Shuffle
F3 0F 70 /r ib                          |PSHUFHW xmm1, xmm2/m128, imm8
VEX.128.F3.0F.WIG 70 /r ib              |VPSHUFHW xmm1, xmm2/m128, imm8
VEX.256.F3.0F.WIG 70 /r ib              |VPSHUFHW ymm1, ymm2/m256, imm8
PSHUFLW—Shuffle
F2 0F 70 /r ib                          |PSHUFLW xmm1, xmm2/m128, imm8
VEX.128.F2.0F.WIG 70 /r ib              |VPSHUFLW xmm1, xmm2/m128, imm8
VEX.256.F2.0F.WIG 70 /r ib              |VPSHUFLW ymm1, ymm2/m256, imm8
PSHUFW—Shuffle
NP 0F 70 /r ib                          |PSHUFW mm1, mm2/m64, imm8
PSIGNB/PSIGNW/PSIGND—Packed
NP 0F 38 08 /r1                         |PSIGNB mm1, mm2/m64
66 0F 38 08 /r                          |PSIGNB xmm1, xmm2/m128
NP 0F 38 09 /r1                         |PSIGNW mm1, mm2/m64
66 0F 38 09 /r                          |PSIGNW xmm1, xmm2/m128
NP 0F 38 0A /r1                         |PSIGND mm1, mm2/m64
66 0F 38 0A /r                          |PSIGND xmm1, xmm2/m128
VEX.128.66.0F38.WIG 08 /r               |VPSIGNB xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.WIG 09 /r               |VPSIGNW xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.WIG 0A /r               |VPSIGND xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.WIG 08 /r               |VPSIGNB ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.WIG 09 /r               |VPSIGNW ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.WIG 0A /r               |VPSIGND ymm1, ymm2, ymm3/m256
PSLLDQ—Shift
66 0F 73 /7 ib                          |PSLLDQ xmm1, imm8
VEX.128.66.0F.WIG 73 /7 ib              |VPSLLDQ xmm1, xmm2, imm8
VEX.256.66.0F.WIG 73 /7 ib              |VPSLLDQ ymm1, ymm2, imm8
PSLLW/PSLLD/PSLLQ—Shift
NP 0F F1 /r1                            |PSLLW mm, mm/m64
66 0F F1 /r                             |PSLLW xmm1, xmm2/m128
NP 0F 71 /6 ib                          |PSLLW mm1, imm8
66 0F 71 /6 ib                          |PSLLW xmm1, imm8
NP 0F F2 /r1                            |PSLLD mm, mm/m64
66 0F F2 /r                             |PSLLD xmm1, xmm2/m128
NP 0F 72 /6 ib1                         |PSLLD mm, imm8
66 0F 72 /6 ib                          |PSLLD xmm1, imm8
NP 0F F3 /r1                            |PSLLQ mm, mm/m64
66 0F F3 /r                             |PSLLQ xmm1, xmm2/m128
NP 0F 73 /6 ib1                         |PSLLQ mm, imm8
66 0F 73 /6 ib                          |PSLLQ xmm1, imm8
VEX.128.66.0F.WIG F1 /r                 |VPSLLW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 71 /6 ib              |VPSLLW xmm1, xmm2, imm8
VEX.128.66.0F.WIG F2 /r                 |VPSLLD xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 72 /6 ib              |VPSLLD xmm1, xmm2, imm8
VEX.128.66.0F.WIG F3 /r                 |VPSLLQ xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 73 /6 ib              |VPSLLQ xmm1, xmm2, imm8
VEX.256.66.0F.WIG F1 /r                 |VPSLLW ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 71 /6 ib              |VPSLLW ymm1, ymm2, imm8
PSLLW/PSLLD/PSLLQ—Shift
VEX.256.66.0F.WIG F2 /r                 |VPSLLD ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 72 /6 ib              |VPSLLD ymm1, ymm2, imm8
VEX.256.66.0F.WIG F3 /r                 |VPSLLQ ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 73 /6 ib              |VPSLLQ ymm1, ymm2, imm8
PSRAW/PSRAD/PSRAQ—Shift
NP 0F E1 /r1                            |PSRAW mm, mm/m64
66 0F E1 /r                             |PSRAW xmm1, xmm2/m128
NP 0F 71 /4 ib1                         |PSRAW mm, imm8
66 0F 71 /4 ib                          |PSRAW xmm1, imm8
NP 0F E2 /r1                            |PSRAD mm, mm/m64
66 0F E2 /r                             |PSRAD xmm1, xmm2/m128
NP 0F 72 /4 ib1                         |PSRAD mm, imm8
66 0F 72 /4 ib                          |PSRAD xmm1, imm8
VEX.128.66.0F.WIG E1 /r                 |VPSRAW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 71 /4 ib              |VPSRAW xmm1, xmm2, imm8
VEX.128.66.0F.WIG E2 /r                 |VPSRAD xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 72 /4 ib              |VPSRAD xmm1, xmm2, imm8
VEX.256.66.0F.WIG E1 /r                 |VPSRAW ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 71 /4 ib              |VPSRAW ymm1, ymm2, imm8
VEX.256.66.0F.WIG E2 /r                 |VPSRAD ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 72 /4 ib              |VPSRAD ymm1, ymm2, imm8
PSRLDQ—Shift
66 0F 73 /3 ib                          |PSRLDQ xmm1, imm8
VEX.128.66.0F.WIG 73 /3 ib              |VPSRLDQ xmm1, xmm2, imm8
VEX.256.66.0F.WIG 73 /3 ib              |VPSRLDQ ymm1, ymm2, imm8
PSRLW/PSRLD/PSRLQ—Shift
NP 0F D1 /r1                            |PSRLW mm, mm/m64
66 0F D1 /r                             |PSRLW xmm1, xmm2/m128
NP 0F 71 /2 ib1                         |PSRLW mm, imm8
66 0F 71 /2 ib                          |PSRLW xmm1, imm8
NP 0F D2 /r1                            |PSRLD mm, mm/m64
66 0F D2 /r                             |PSRLD xmm1, xmm2/m128
NP 0F 72 /2 ib1                         |PSRLD mm, imm8
66 0F 72 /2 ib                          |PSRLD xmm1, imm8
NP 0F D3 /r1                            |PSRLQ mm, mm/m64
66 0F D3 /r                             |PSRLQ xmm1, xmm2/m128
NP 0F 73 /2 ib1                         |PSRLQ mm, imm8
66 0F 73 /2 ib                          |PSRLQ xmm1, imm8
VEX.128.66.0F.WIG D1 /r                 |VPSRLW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 71 /2 ib              |VPSRLW xmm1, xmm2, imm8
VEX.128.66.0F.WIG D2 /r                 |VPSRLD xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 72 /2 ib              |VPSRLD xmm1, xmm2, imm8
VEX.128.66.0F.WIG D3 /r                 |VPSRLQ xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 73 /2 ib              |VPSRLQ xmm1, xmm2, imm8
VEX.256.66.0F.WIG D1 /r                 |VPSRLW ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 71 /2 ib              |VPSRLW ymm1, ymm2, imm8
PSRLW/PSRLD/PSRLQ—Shift
VEX.256.66.0F.WIG D2 /r                 |VPSRLD ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 72 /2 ib              |VPSRLD ymm1, ymm2, imm8
VEX.256.66.0F.WIG D3 /r                 |VPSRLQ ymm1, ymm2, xmm3/m128
VEX.256.66.0F.WIG 73 /2 ib              |VPSRLQ ymm1, ymm2, imm8
PSUBB/PSUBW/PSUBD—Subtract
NP 0F F8 /r1                            |PSUBB mm, mm/m64
66 0F F8 /r                             |PSUBB xmm1, xmm2/m128
NP 0F F9 /r1                            |PSUBW mm, mm/m64
66 0F F9 /r                             |PSUBW xmm1, xmm2/m128
NP 0F FA /r1                            |PSUBD mm, mm/m64
66 0F FA /r                             |PSUBD xmm1, xmm2/m128
VEX.128.66.0F.WIG F8 /r                 |VPSUBB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG F9 /r                 |VPSUBW xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG FA /r                 |VPSUBD xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG F8 /r                 |VPSUBB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG F9 /r                 |VPSUBW ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG FA /r                 |VPSUBD ymm1, ymm2, ymm3/m256
PSUBQ—Subtract
NP 0F FB /r1                            |PSUBQ mm1, mm2/m64
66 0F FB /r                             |PSUBQ xmm1, xmm2/m128
VEX.128.66.0F.WIG FB/r                  |VPSUBQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG FB /r                 |VPSUBQ ymm1, ymm2, ymm3/m256
PSUBSB/PSUBSW—Subtract
NP 0F E8 /r1                            |PSUBSB mm, mm/m64
66 0F E8 /r                             |PSUBSB xmm1, xmm2/m128
NP 0F E9 /r1                            |PSUBSW mm, mm/m64
66 0F E9 /r                             |PSUBSW xmm1, xmm2/m128
VEX.128.66.0F.WIG E8 /r                 |VPSUBSB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG E9 /r                 |VPSUBSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG E8 /r                 |VPSUBSB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG E9 /r                 |VPSUBSW ymm1, ymm2, ymm3/m256
PSUBUSB/PSUBUSW—Subtract
NP 0F D8 /r1                            |PSUBUSB mm, mm/m64
66 0F D8 /r                             |PSUBUSB xmm1, xmm2/m128
NP 0F D9 /r1                            |PSUBUSW mm, mm/m64
66 0F D9 /r                             |PSUBUSW xmm1, xmm2/m128
VEX.128.66.0F.WIG D8 /r                 |VPSUBUSB xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG D9 /r                 |VPSUBUSW xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG D8 /r                 |VPSUBUSB ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG D9 /r                 |VPSUBUSW ymm1, ymm2, ymm3/m256
PTEST—Logical
66 0F 38 17 /r                          |PTEST xmm1, xmm2/m128
VEX.128.66.0F38.WIG 17 /r               |VPTEST xmm1, xmm2/m128
VEX.256.66.0F38.WIG 17 /r               |VPTEST ymm1, ymm2/m256
PTWRITE—Write
F3 REX.W 0F AE /4                       |PTWRITE r64/m64
F3 0F AE /4                             |PTWRITE r32/m32
PUNPCKHBW/PUNPCKHWD/PUNPCKHDQ/PUNPCKHQDQ—
NP 0F 68 /r1                            |PUNPCKHBW mm, mm/m64
66 0F 68 /r                             |PUNPCKHBW xmm1, xmm2/m128
NP 0F 69 /r1                            |PUNPCKHWD mm, mm/m64
66 0F 69 /r                             |PUNPCKHWD xmm1, xmm2/m128
NP 0F 6A /r1                            |PUNPCKHDQ mm, mm/m64
66 0F 6A /r                             |PUNPCKHDQ xmm1, xmm2/m128
66 0F 6D /r                             |PUNPCKHQDQ xmm1, xmm2/m128
VEX.128.66.0F.WIG 68/r                  |VPUNPCKHBW xmm1,xmm2, xmm3/m128
VEX.128.66.0F.WIG 69/r                  |VPUNPCKHWD xmm1,xmm2, xmm3/m128
VEX.128.66.0F.WIG 6A/r                  |VPUNPCKHDQ xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 6D/r                  |VPUNPCKHQDQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 68 /r                 |VPUNPCKHBW ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 69 /r                 |VPUNPCKHWD ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 6A /r                 |VPUNPCKHDQ ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 6D /r                 |VPUNPCKHQDQ ymm1, ymm2, ymm3/m256
PUNPCKLBW/PUNPCKLWD/PUNPCKLDQ/PUNPCKLQDQ—Unpack
NP 0F 60 /r1                            |PUNPCKLBW mm, mm/m32
66 0F 60 /r                             |PUNPCKLBW xmm1, xmm2/m128
NP 0F 61 /r1                            |PUNPCKLWD mm, mm/m32
66 0F 61 /r                             |PUNPCKLWD xmm1, xmm2/m128
NP 0F 62 /r1                            |PUNPCKLDQ mm, mm/m32
66 0F 62 /r                             |PUNPCKLDQ xmm1, xmm2/m128
66 0F 6C /r                             |PUNPCKLQDQ xmm1, xmm2/m128
VEX.128.66.0F.WIG 60/r                  |VPUNPCKLBW xmm1,xmm2, xmm3/m128
VEX.128.66.0F.WIG 61/r                  |VPUNPCKLWD xmm1,xmm2, xmm3/m128
VEX.128.66.0F.WIG 62/r                  |VPUNPCKLDQ xmm1, xmm2, xmm3/m128
VEX.128.66.0F.WIG 6C/r                  |VPUNPCKLQDQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG 60 /r                 |VPUNPCKLBW ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 61 /r                 |VPUNPCKLWD ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 62 /r                 |VPUNPCKLDQ ymm1, ymm2, ymm3/m256
VEX.256.66.0F.WIG 6C /r                 |VPUNPCKLQDQ ymm1, ymm2, ymm3/m256
PUSH—Push
FF /6                                   |PUSH r/m16
FF /6                                   |PUSH r/m64
50+rw                                   |PUSH r16
50+rd                                   |PUSH r64
6A ib                                   |PUSH imm8
68 iw                                   |PUSH imm16
68 id                                   |PUSH imm32
0F A0                                   |PUSH FS
0F A8                                   |PUSH GS
PUSHF/PUSHFD/PUSHFQ—Push
9C                                      |PUSHF
9C                                      |PUSHFQ
PXOR—Logical
NP 0F EF /r1                            |PXOR mm, mm/m64
66 0F EF /r                             |PXOR xmm1, xmm2/m128
VEX.128.66.0F.WIG EF /r                 |VPXOR xmm1, xmm2, xmm3/m128
VEX.256.66.0F.WIG EF /r                 |VPXOR ymm1, ymm2, ymm3/m256
RCL/RCR/ROL/ROR—Rotate
D0 /2                                   |RCL r/m8, 1
REX + D0 /2                             |RCL r/m8, 1
D2 /2                                   |RCL r/m8, CL
REX + D2 /2                             |RCL r/m8, CL
C0 /2 ib                                |RCL r/m8, imm8
REX + C0 /2 ib                          |RCL r/m8, imm8
D1 /2                                   |RCL r/m16, 1
D3 /2                                   |RCL r/m16, CL
C1 /2 ib                                |RCL r/m16, imm8
D1 /2                                   |RCL r/m32, 1
REX.W + D1 /2                           |RCL r/m64, 1
D3 /2                                   |RCL r/m32, CL
REX.W + D3 /2                           |RCL r/m64, CL
C1 /2 ib                                |RCL r/m32, imm8
REX.W + C1 /2 ib                        |RCL r/m64, imm8
D0 /3                                   |RCR r/m8, 1
REX + D0 /3                             |RCR r/m8, 1
D2 /3                                   |RCR r/m8, CL
REX + D2 /3                             |RCR r/m8, CL
C0 /3 ib                                |RCR r/m8, imm8
REX + C0 /3 ib                          |RCR r/m8, imm8
D1 /3                                   |RCR r/m16, 1
D3 /3                                   |RCR r/m16, CL
C1 /3 ib                                |RCR r/m16, imm8
D1 /3                                   |RCR r/m32, 1
REX.W + D1 /3                           |RCR r/m64, 1
D3 /3                                   |RCR r/m32, CL
REX.W + D3 /3                           |RCR r/m64, CL
C1 /3 ib                                |RCR r/m32, imm8
REX.W + C1 /3 ib                        |RCR r/m64, imm8
D0 /0                                   |ROL r/m8, 1
REX + D0 /0                             |ROL r/m8, 1
D2 /0                                   |ROL r/m8, CL
REX + D2 /0                             |ROL r/m8, CL
C0 /0 ib                                |ROL r/m8, imm8
RCL/RCR/ROL/ROR—Rotate
REX + C0 /0 ib                          |ROL r/m8, imm8
D1 /0                                   |ROL r/m16, 1
D3 /0                                   |ROL r/m16, CL
C1 /0 ib                                |ROL r/m16, imm8
D1 /0                                   |ROL r/m32, 1
REX.W + D1 /0                           |ROL r/m64, 1
D3 /0                                   |ROL r/m32, CL
REX.W + D3 /0                           |ROL r/m64, CL
C1 /0 ib                                |ROL r/m32, imm8
REX.W + C1 /0 ib                        |ROL r/m64, imm8
D0 /1                                   |ROR r/m8, 1
REX + D0 /1                             |ROR r/m8, 1
D2 /1                                   |ROR r/m8, CL
REX + D2 /1                             |ROR r/m8, CL
C0 /1 ib                                |ROR r/m8, imm8
REX + C0 /1 ib                          |ROR r/m8, imm8
D1 /1                                   |ROR r/m16, 1
D3 /1                                   |ROR r/m16, CL
C1 /1 ib                                |ROR r/m16, imm8
D1 /1                                   |ROR r/m32, 1
REX.W + D1 /1                           |ROR r/m64, 1
D3 /1                                   |ROR r/m32, CL
REX.W + D3 /1                           |ROR r/m64, CL
C1 /1 ib                                |ROR r/m32, imm8
REX.W + C1 /1 ib                        |ROR r/m64, imm8
RCPPS—Compute
NP 0F 53 /r                             |RCPPS xmm1, xmm2/m128
VEX.128.0F.WIG 53 /r                    |VRCPPS xmm1, xmm2/m128
VEX.256.0F.WIG 53 /r                    |VRCPPS ymm1, ymm2/m256
RCPSS—Compute
F3 0F 53 /r                             |RCPSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 53 /r                 |VRCPSS xmm1, xmm2, xmm3/m32
RDFSBASE/RDGSBASE—Read
F3 0F AE /0                             |RDFSBASE r32
F3 REX.W 0F AE /0                       |RDFSBASE r64
F3 0F AE /1                             |RDGSBASE r32
F3 REX.W 0F AE /1                       |RDGSBASE r64
RDMSR—Read
0F 32                                   |RDMSR
RDPID—Read
F3 0F C7 /7                             |RDPID r64
RDPKRU—Read
NP 0F 01 EE                             |RDPKRU
RDPMC—Read
0F 33                                   |RDPMC
RDRAND—Read
NFx 0F C7 /6                            |RDRAND r16
NFx 0F C7 /6                            |RDRAND r32
NFx REX.W + 0F C7 /6                    |RDRAND r64
RDSEED—Read
NFx 0F C7 /7                            |RDSEED r16
NFx 0F C7 /7                            |RDSEED r32
NFx REX.W + 0F C7 /7                    |RDSEED r64
RDSSPD/RDSSPQ—Read
F3 0F 1E /1 (mod=11)                    |RDSSPD r32
F3 REX.W 0F 1E /1 (mod=11)              |RDSSPQ r64
RDTSC—Read
0F 31                                   |RDTSC
RDTSCP—Read
0F 01 F9                                |RDTSCP
REP/REPE/REPZ/REPNE/REPNZ—Repeat
F3 6C                                   |REP INS m8, DX
F3 6C                                   |REP INS m8, DX
F3 6D                                   |REP INS m16, DX
F3 6D                                   |REP INS m32, DX
F3 6D                                   |REP INS r/m32, DX
F3 A4                                   |REP MOVS m8, m8
F3 REX.W A4                             |REP MOVS m8, m8
F3 A5                                   |REP MOVS m16, m16
F3 A5                                   |REP MOVS m32, m32
F3 REX.W A5                             |REP MOVS m64, m64
F3 6E                                   |REP OUTS DX, r/m8
F3 REX.W 6E                             |REP OUTS DX, r/m8
F3 6F                                   |REP OUTS DX, r/m16
F3 6F                                   |REP OUTS DX, r/m32
F3 REX.W 6F                             |REP OUTS DX, r/m32
F3 AC                                   |REP LODS AL
F3 REX.W AC                             |REP LODS AL
F3 AD                                   |REP LODS AX
F3 AD                                   |REP LODS EAX
F3 REX.W AD                             |REP LODS RAX
F3 AA                                   |REP STOS m8
F3 REX.W AA                             |REP STOS m8
F3 AB                                   |REP STOS m16
F3 AB                                   |REP STOS m32
F3 REX.W AB                             |REP STOS m64
F3 A6                                   |REPE CMPS m8, m8
F3 REX.W A6                             |REPE CMPS m8, m8
F3 A7                                   |REPE CMPS m16, m16
F3 A7                                   |REPE CMPS m32, m32
F3 REX.W A7                             |REPE CMPS m64, m64
F3 AE                                   |REPE SCAS m8
F3 REX.W AE                             |REPE SCAS m8
F3 AF                                   |REPE SCAS m16
F3 AF                                   |REPE SCAS m32
REP/REPE/REPZ/REPNE/REPNZ—Repeat
F3 REX.W AF                             |REPE SCAS m64
F2 A6                                   |REPNE CMPS m8, m8
F2 REX.W A6                             |REPNE CMPS m8, m8
F2 A7                                   |REPNE CMPS m16, m16
F2 A7                                   |REPNE CMPS m32, m32
F2 REX.W A7                             |REPNE CMPS m64, m64
F2 AE                                   |REPNE SCAS m8
F2 REX.W AE                             |REPNE SCAS m8
F2 AF                                   |REPNE SCAS m16
F2 AF                                   |REPNE SCAS m32
F2 REX.W AF                             |REPNE SCAS m64
RET—Return
C3                                      |RET
CB                                      |RET
C2 iw                                   |RET imm16
CA iw                                   |RET imm16
ROUNDPD—Round
66 0F 3A 09 /r ib                       |ROUNDPD xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 09 /r ib            |VROUNDPD xmm1, xmm2/m128, imm8
VEX.256.66.0F3A.WIG 09 /r ib            |VROUNDPD ymm1, ymm2/m256, imm8
ROUNDPS—Round
66 0F 3A 08                             |/r ibROUNDPS xmm1, xmm2/m128, imm8
VEX.128.66.0F3A.WIG 08 /r ib            |VROUNDPS xmm1, xmm2/m128, imm8
VEX.256.66.0F3A.WIG 08 /r ib            |VROUNDPS ymm1, ymm2/m256, imm8
ROUNDSD—Round
66 0F 3A 0B /r ib                       |ROUNDSD xmm1, xmm2/m64, imm8
VEX.LIG.66.0F3A.WIG 0B /r ib            |VROUNDSD xmm1, xmm2, xmm3/m64, imm8
ROUNDSS—Round
66 0F 3A 0A /r ib                       |ROUNDSS xmm1, xmm2/m32, imm8
VEX.LIG.66.0F3A.WIG 0A /r ib            |VROUNDSS xmm1, xmm2, xmm3/m32, imm8
RSM—Resume
0F AA                                   |RSM
RSQRTPS—Compute
NP 0F 52 /r                             |RSQRTPS xmm1, xmm2/m128
VEX.128.0F.WIG 52 /r                    |VRSQRTPS xmm1, xmm2/m128
VEX.256.0F.WIG 52 /r                    |VRSQRTPS ymm1, ymm2/m256
RSQRTSS—Compute
F3 0F 52 /r                             |RSQRTSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 52 /r                 |VRSQRTSS xmm1, xmm2, xmm3/m32
RSTORSSP—Restore
F3 0F 01 /5 (mod!=11, /5, memory only)  |RSTORSSP m64
SAL/SAR/SHL/SHR—Shift
D0 /4                                   |SAL r/m8, 1
REX + D0 /4                             |SAL r/m8, 1
D2 /4                                   |SAL r/m8, CL
REX + D2 /4                             |SAL r/m8, CL
C0 /4 ib                                |SAL r/m8, imm8
REX + C0 /4 ib                          |SAL r/m8, imm8
D1 /4                                   |SAL r/m16, 1
D3 /4                                   |SAL r/m16, CL
C1 /4 ib                                |SAL r/m16, imm8
D1 /4                                   |SAL r/m32, 1
REX.W + D1 /4                           |SAL r/m64, 1
D3 /4                                   |SAL r/m32, CL
REX.W + D3 /4                           |SAL r/m64, CL
C1 /4 ib                                |SAL r/m32, imm8
REX.W + C1 /4 ib                        |SAL r/m64, imm8
D0 /7                                   |SAR r/m8, 1
REX + D0 /7                             |SAR r/m8, 1
D2 /7                                   |SAR r/m8, CL
REX + D2 /7                             |SAR r/m8, CL
C0 /7 ib                                |SAR r/m8, imm8
REX + C0 /7 ib                          |SAR r/m8, imm8
D1 /7                                   |SAR r/m16,1
D3 /7                                   |SAR r/m16, CL
C1 /7 ib                                |SAR r/m16, imm8
D1 /7                                   |SAR r/m32, 1
REX.W + D1 /7                           |SAR r/m64, 1
D3 /7                                   |SAR r/m32, CL
REX.W + D3 /7                           |SAR r/m64, CL
C1 /7 ib                                |SAR r/m32, imm8
REX.W + C1 /7 ib                        |SAR r/m64, imm8
D0 /4                                   |SHL r/m8, 1
REX + D0 /4                             |SHL r/m8, 1
D2 /4                                   |SHL r/m8, CL
REX + D2 /4                             |SHL r/m8, CL
C0 /4 ib                                |SHL r/m8, imm8
REX + C0 /4 ib                          |SHL r/m8, imm8
D1 /4                                   |SHL r/m16,1
D3 /4                                   |SHL r/m16, CL
C1 /4 ib                                |SHL r/m16, imm8
D1 /4                                   |SHL r/m32,1
SAL/SAR/SHL/SHR—Shift
REX.W + D1 /4                           |SHL r/m64,1
D3 /4                                   |SHL r/m32, CL
REX.W + D3 /4                           |SHL r/m64, CL
C1 /4 ib                                |SHL r/m32, imm8
REX.W + C1 /4 ib                        |SHL r/m64, imm8
D0 /5                                   |SHR r/m8,1
REX + D0 /5                             |SHR r/m8, 1
D2 /5                                   |SHR r/m8, CL
REX + D2 /5                             |SHR r/m8, CL
C0 /5 ib                                |SHR r/m8, imm8
REX + C0 /5 ib                          |SHR r/m8, imm8
D1 /5                                   |SHR r/m16, 1
D3 /5                                   |SHR r/m16, CL
C1 /5 ib                                |SHR r/m16, imm8
D1 /5                                   |SHR r/m32, 1
REX.W + D1 /5                           |SHR r/m64, 1
D3 /5                                   |SHR r/m32, CL
REX.W + D3 /5                           |SHR r/m64, CL
C1 /5 ib                                |SHR r/m32, imm8
REX.W + C1 /5 ib                        |SHR r/m64, imm8
SARX/SHLX/SHRX—Shift
VEX.LZ.F3.0F38.W0 F7 /r                 |SARX r32a, r/m32, r32b
VEX.LZ.66.0F38.W0 F7 /r                 |SHLX r32a, r/m32, r32b
VEX.LZ.F2.0F38.W0 F7 /r                 |SHRX r32a, r/m32, r32b
VEX.LZ.F3.0F38.W1 F7 /r                 |SARX r64a, r/m64, r64b
VEX.LZ.66.0F38.W1 F7 /r                 |SHLX r64a, r/m64, r64b
VEX.LZ.F2.0F38.W1 F7 /r                 |SHRX r64a, r/m64, r64b
SAVEPREVSSP—Save
F3 0F 01 EA (mod!=11, /5, RM=010)       |SAVEPREVSSP
SBB—Integer
1C ib                                   |SBB AL, imm8
1D iw                                   |SBB AX, imm16
1D id                                   |SBB EAX, imm32
REX.W + 1D id                           |SBB RAX, imm32
80 /3 ib                                |SBB r/m8, imm8
REX + 80 /3 ib                          |SBB r/m8, imm8
81 /3 iw                                |SBB r/m16, imm16
81 /3 id                                |SBB r/m32, imm32
REX.W + 81 /3 id                        |SBB r/m64, imm32
83 /3 ib                                |SBB r/m16, imm8
83 /3 ib                                |SBB r/m32, imm8
REX.W + 83 /3 ib                        |SBB r/m64, imm8
18 /r                                   |SBB r/m8, r8
REX + 18 /r                             |SBB r/m8, r8
19 /r                                   |SBB r/m16, r16
19 /r                                   |SBB r/m32, r32
REX.W + 19 /r                           |SBB r/m64, r64
1A /r                                   |SBB r8, r/m8
REX + 1A /r                             |SBB r8, r/m8
1B /r                                   |SBB r16, r/m16
1B /r                                   |SBB r32, r/m32
REX.W + 1B /r                           |SBB r64, r/m64
SCAS/SCASB/SCASW/SCASD—Scan
AE                                      |SCAS m8
AF                                      |SCAS m16
AF                                      |SCAS m32
REX.W + AF                              |SCAS m64
AE                                      |SCASB
AF                                      |SCASW
AF                                      |SCASD
REX.W + AF                              |SCASQ
SENDUIPI—Send
F3 0F C7 /6                             |SENDUIPI reg
SERIALIZE—Serialize
NP 0F 01 E8                             |SERIALIZE
SETcc—Set
0F 97                                   |SETA r/m8
REX + 0F 97                             |SETA r/m8
0F 93                                   |SETAE r/m8
REX + 0F 93                             |SETAE r/m8
0F 92                                   |SETB r/m8
REX + 0F 92                             |SETB r/m8
0F 96                                   |SETBE r/m8
REX + 0F 96                             |SETBE r/m8
0F 92                                   |SETC r/m8
REX + 0F 92                             |SETC r/m8
0F 94                                   |SETE r/m8
REX + 0F 94                             |SETE r/m8
0F 9F                                   |SETG r/m8
REX + 0F 9F                             |SETG r/m8
0F 9D                                   |SETGE r/m8
REX + 0F 9D                             |SETGE r/m8
0F 9C                                   |SETL r/m8
REX + 0F 9C                             |SETL r/m8
0F 9E                                   |SETLE r/m8
REX + 0F 9E                             |SETLE r/m8
0F 96                                   |SETNA r/m8
REX + 0F 96                             |SETNA r/m8
0F 92                                   |SETNAE r/m8
REX + 0F 92                             |SETNAE r/m8
0F 93                                   |SETNB r/m8
REX + 0F 93                             |SETNB r/m8
0F 97                                   |SETNBE r/m8
REX + 0F 97                             |SETNBE r/m8
0F 93                                   |SETNC r/m8
REX + 0F 93                             |SETNC r/m8
0F 95                                   |SETNE r/m8
REX + 0F 95                             |SETNE r/m8
0F 9E                                   |SETNG r/m8
REX + 0F 9E                             |SETNG r/m8
0F 9C                                   |SETNGE r/m8
REX + 0F 9C                             |SETNGE r/m8
0F 9D                                   |SETNL r/m8
REX + 0F 9D                             |SETNL r/m8
0F 9F                                   |SETNLE r/m8
REX + 0F 9F                             |SETNLE r/m8
SETcc—Set
0F 91                                   |SETNO r/m8
REX + 0F 91                             |SETNO r/m8
0F 9B                                   |SETNP r/m8
REX + 0F 9B                             |SETNP r/m8
0F 99                                   |SETNS r/m8
REX + 0F 99                             |SETNS r/m8
0F 95                                   |SETNZ r/m8
REX + 0F 95                             |SETNZ r/m8
0F 90                                   |SETO r/m8
REX + 0F 90                             |SETO r/m8
0F 9A                                   |SETP r/m8
REX + 0F 9A                             |SETP r/m8
0F 9A                                   |SETPE r/m8
REX + 0F 9A                             |SETPE r/m8
0F 9B                                   |SETPO r/m8
REX + 0F 9B                             |SETPO r/m8
0F 98                                   |SETS r/m8
REX + 0F 98                             |SETS r/m8
0F 94                                   |SETZ r/m8
REX + 0F 94                             |SETZ r/m8
SETSSBSY—Mark
F3 0F 01 E8                             |SETSSBSY
SFENCE—Store
NP 0F AE F8                             |SFENCE
SGDT—Store
0F 01 /0                                |SGDT m
SHA1RNDS4—Perform
NP 0F 3A CC /r ib                       |SHA1RNDS4 xmm1,xmm2/m128, imm8
SHA1NEXTE—Calculate
NP 0F 38 C8 /r                          |SHA1NEXTE xmm1,xmm2/m128
SHA1MSG1—Perform
NP 0F 38 C9 /r                          |SHA1MSG1 xmm1,xmm2/m128
SHA1MSG2—Perform
NP 0F 38 CA /r                          |SHA1MSG2 xmm1,xmm2/m128
SHA256RNDS2—Perform
NP 0F 38 CB /r                          |SHA256RNDS2 xmm1,xmm2/m128, <XMM0>
SHA256MSG1—Perform
NP 0F 38 CC /r                          |SHA256MSG1 xmm1,xmm2/m128
SHA256MSG2—Perform
NP 0F 38 CD /r                          |SHA256MSG2 xmm1,xmm2/m128
SHLD—Double
0F A4 /r ib                             |SHLD r/m16, r16, imm8
0F A5 /r                                |SHLD r/m16, r16, CL
0F A4 /r ib                             |SHLD r/m32, r32, imm8
REX.W + 0F A4 /r ib                     |SHLD r/m64, r64, imm8
0F A5 /r                                |SHLD r/m32, r32, CL
REX.W + 0F A5 /r                        |SHLD r/m64, r64, CL
SHRD—Double
0F AC /r ib                             |SHRD r/m16, r16, imm8
0F AD /r                                |SHRD r/m16, r16, CL
0F AC /r ib                             |SHRD r/m32, r32, imm8
REX.W + 0F AC /r ib                     |SHRD r/m64, r64, imm8
0F AD /r                                |SHRD r/m32, r32, CL
REX.W + 0F AD /r                        |SHRD r/m64, r64, CL
SHUFPD—Packed
66 0F C6 /r ib                          |SHUFPD xmm1, xmm2/m128, imm8
VEX.128.66.0F.WIG C6 /r ib              |VSHUFPD xmm1, xmm2, xmm3/m128,imm8
VEX.256.66.0F.WIG C6 /r ib              |VSHUFPD ymm1, ymm2, ymm3/m256,imm8
SHUFPS—Packed
NP 0F C6 /r ib                          |SHUFPS xmm1, xmm3/m128, imm8
VEX.128.0F.WIG C6 /r ib                 |VSHUFPS xmm1, xmm2, xmm3/m128,imm8
VEX.256.0F.WIG C6 /r ib                 |VSHUFPS ymm1, ymm2, ymm3/m256,imm8
SIDT—Store
0F 01 /1                                |SIDT m
SLDT—Store
0F 00 /0                                |SLDT r/m16
SMSW—Store
0F 01 /4                                |SMSW r/m16
0F 01 /4                                |SMSW r32/m16
REX.W + 0F 01 /4                        |SMSW r64/m16
SQRTPD—Square
66 0F 51 /r                             |SQRTPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 51 /r                 |VSQRTPD xmm1, xmm2/m128
VEX.256.66.0F.WIG 51 /r                 |VSQRTPD ymm1, ymm2/m256
SQRTPS—Square
NP 0F 51 /r                             |SQRTPS xmm1, xmm2/m128
VEX.128.0F.WIG 51 /r                    |VSQRTPS xmm1, xmm2/m128
VEX.256.0F.WIG 51/r                     |VSQRTPS ymm1, ymm2/m256
SQRTSD—Compute
F2 0F 51/r                              |SQRTSD xmm1,xmm2/m64
VEX.LIG.F2.0F.WIG 51/r                  |VSQRTSD xmm1,xmm2, xmm3/m64
SQRTSS—Compute
F3 0F 51 /r                             |SQRTSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 51 /r                 |VSQRTSS xmm1, xmm2,xmm3/m32
STAC—Set
NP 0F 01 CB                             |STAC
STC—Set
F9                                      |STC
STD—Set
FD                                      |STD
STI—Set
FB                                      |STI
STMXCSR—Store
NP 0F AE /3                             |STMXCSR m32
VEX.LZ.0F.WIG AE /3                     |VSTMXCSR m32
STOS/STOSB/STOSW/STOSD/STOSQ—Store
AA                                      |STOS m8
AB                                      |STOS m16
AB                                      |STOS m32
REX.W + AB                              |STOS m64
AA                                      |STOSB
AB                                      |STOSW
AB                                      |STOSD
REX.W + AB                              |STOSQ
STR—Store
0F 00 /1                                |STR r/m16
STTILECFG—Store
VEX.128.66.0F38.W0 49 !(11):000:bbb     |STTILECFG m512
STUI—Set
F3 0F 01 EF                             |STUI
SUB—Subtract
2C ib                                   |SUB AL, imm8
2D iw                                   |SUB AX, imm16
2D id                                   |SUB EAX, imm32
REX.W + 2D id                           |SUB RAX, imm32
80 /5 ib                                |SUB r/m8, imm8
REX + 80 /5 ib                          |SUB r/m8, imm8
81 /5 iw                                |SUB r/m16, imm16
81 /5 id                                |SUB r/m32, imm32
REX.W + 81 /5 id                        |SUB r/m64, imm32
83 /5 ib                                |SUB r/m16, imm8
83 /5 ib                                |SUB r/m32, imm8
REX.W + 83 /5 ib                        |SUB r/m64, imm8
28 /r                                   |SUB r/m8, r8
REX + 28 /r                             |SUB r/m8, r8
29 /r                                   |SUB r/m16, r16
29 /r                                   |SUB r/m32, r32
REX.W + 29 /r                           |SUB r/m64, r64
2A /r                                   |SUB r8, r/m8
REX + 2A /r                             |SUB r8, r/m8
2B /r                                   |SUB r16, r/m16
2B /r                                   |SUB r32, r/m32
REX.W + 2B /r                           |SUB r64, r/m64
SUBPD—Subtract
66 0F 5C /r                             |SUBPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 5C /r                 |VSUBPD xmm1,xmm2, xmm3/m128
VEX.256.66.0F.WIG 5C /r                 |VSUBPD ymm1, ymm2, ymm3/m256
SUBPS—Subtract
NP 0F 5C /r                             |SUBPS xmm1, xmm2/m128
VEX.128.0F.WIG 5C /r                    |VSUBPS xmm1,xmm2, xmm3/m128
VEX.256.0F.WIG 5C /r                    |VSUBPS ymm1, ymm2, ymm3/m256
SUBSD—Subtract
F2 0F 5C /r                             |SUBSD xmm1, xmm2/m64
VEX.LIG.F2.0F.WIG 5C /r                 |VSUBSD xmm1,xmm2, xmm3/m64
SUBSS—Subtract
F3 0F 5C /r                             |SUBSS xmm1, xmm2/m32
VEX.LIG.F3.0F.WIG 5C /r                 |VSUBSS xmm1,xmm2, xmm3/m32
SWAPGS—Swap
0F 01 F8                                |SWAPGS
SYSCALL—Fast
0F 05                                   |SYSCALL
SYSENTER—Fast
0F 34                                   |SYSENTER
SYSEXIT—Fast
0F 35                                   |SYSEXIT
REX.W + 0F 35                           |SYSEXIT
SYSRET—Return
0F 07                                   |SYSRET
REX.W + 0F 07                           |SYSRET
TDPBF16PS—Dot
VEX.128.F3.0F38.W0 5C 11:rrr:bbb        |TDPBF16PS tmm1, tmm2, tmm3
TDPBSSD/TDPBSUD/TDPBUSD/TDPBUUD—Dot
VEX.128.F2.0F38.W0 5E 11:rrr:bbb        |TDPBSSD tmm1, tmm2, tmm3
VEX.128.F3.0F38.W0 5E 11:rrr:bbb        |TDPBSUD tmm1, tmm2, tmm3
VEX.128.66.0F38.W0 5E 11:rrr:bbb        |TDPBUSD tmm1, tmm2, tmm3
VEX.128.NP.0F38.W0 5E 11:rrr:bbb        |TDPBUUD tmm1, tmm2, tmm3
TEST—Logical
A8 ib                                   |TEST AL, imm8
A9 iw                                   |TEST AX, imm16
A9 id                                   |TEST EAX, imm32
REX.W + A9 id                           |TEST RAX, imm32
F6 /0 ib                                |TEST r/m8, imm8
REX + F6 /0 ib                          |TEST r/m8, imm8
F7 /0 iw                                |TEST r/m16, imm16
F7 /0 id                                |TEST r/m32, imm32
REX.W + F7 /0 id                        |TEST r/m64, imm32
84 /r                                   |TEST r/m8, r8
REX + 84 /r                             |TEST r/m8, r8
85 /r                                   |TEST r/m16, r16
85 /r                                   |TEST r/m32, r32
REX.W + 85 /r                           |TEST r/m64, r64
TESTUI—Determine
F3 0F 01 ED                             |TESTUI
TILELOADD/TILELOADDT1—Load
VEX.128.F2.0F38.W0 4B !(11):rrr:100     |TILELOADD tmm1, sibmem
VEX.128.66.0F38.W0 4B !(11):rrr:100     |TILELOADDT1 tmm1, sibmem
TILERELEASE—Release
VEX.128.NP.0F38.W0 49 C0                |TILERELEASE
TILESTORED—Store
VEX.128.F3.0F38.W0 4B !(11):rrr:100     |TILESTORED sibmem, tmm1
TILEZERO—Zero
VEX.128.F2.0F38.W0 49 11:rrr:000        |TILEZERO tmm1
TPAUSE—Timed
66 0F AE /6                             |TPAUSE r32, <edx>, <eax>
TZCNT—Count
F3 0F BC /r                             |TZCNT r16, r/m16
F3 0F BC /r                             |TZCNT r32, r/m32
F3 REX.W 0F BC /r                       |TZCNT r64, r/m64
UCOMISD—Unordered
66 0F 2E /r                             |UCOMISD xmm1, xmm2/m64
VEX.LIG.66.0F.WIG 2E /r                 |VUCOMISD xmm1, xmm2/m64
UCOMISS—Unordered
NP 0F 2E /r                             |UCOMISS xmm1, xmm2/m32
VEX.LIG.0F.WIG 2E /r                    |VUCOMISS xmm1, xmm2/m32
UD—Undefined
0F FF /r                                |UD01 r32, r/m32
0F B9 /r                                |UD1 r32, r/m32
0F 0B                                   |UD2
UIRET—User-Interrupt
F3 0F 01 EC                             |UIRET
UMONITOR—User
F3 0F AE /6                             |UMONITOR r16/r32/r64
UMWAIT—User
F2 0F AE /6                             |UMWAIT r32, <edx>, <eax>
UNPCKHPD—Unpack
66 0F 15 /r                             |UNPCKHPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 15 /r                 |VUNPCKHPD xmm1,xmm2,xmm3/m128
VEX.256.66.0F.WIG 15 /r                 |VUNPCKHPD ymm1,ymm2,ymm3/m256
UNPCKHPS—Unpack
NP 0F 15 /r                             |UNPCKHPS xmm1, xmm2/m128
VEX.128.0F.WIG 15 /r                    |VUNPCKHPS xmm1, xmm2,xmm3/m128
VEX.256.0F.WIG 15 /r                    |VUNPCKHPS ymm1, ymm2,ymm3/m256
UNPCKLPD—Unpack
66 0F 14 /r                             |UNPCKLPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 14 /r                 |VUNPCKLPD xmm1,xmm2,xmm3/m128
VEX.256.66.0F.WIG 14 /r                 |VUNPCKLPD ymm1,ymm2,ymm3/m256
UNPCKLPS—Unpack
NP 0F 14 /r                             |UNPCKLPS xmm1, xmm2/m128
VEX.128.0F.WIG 14 /r                    |VUNPCKLPS xmm1,xmm2,xmm3/m128
VEX.256.0F.WIG 14 /r                    |VUNPCKLPSymm1,ymm2,ymm3/m256
VBROADCAST—Load
VEX.128.66.0F38.W0 18 /r                |VBROADCASTSS xmm1, m32
VEX.256.66.0F38.W0 18 /r                |VBROADCASTSS ymm1, m32
VEX.256.66.0F38.W0 19 /r                |VBROADCASTSD ymm1, m64
VEX.256.66.0F38.W0 1A /r                |VBROADCASTF128 ymm1, m128
VEX.128.66.0F38.W0 18/r                 |VBROADCASTSS xmm1, xmm2
VEX.256.66.0F38.W0 18 /r                |VBROADCASTSS ymm1, xmm2
VEX.256.66.0F38.W0 19 /r                |VBROADCASTSD ymm1, xmm2
VCVTPH2PS/VCVTPH2PSX—Convert
VEX.128.66.0F38.W0 13 /r                |VCVTPH2PS xmm1, xmm2/m64
VEX.256.66.0F38.W0 13 /r                |VCVTPH2PS ymm1, xmm2/m128
VCVTPS2PH—Convert
VEX.128.66.0F3A.W0 1D /r ib             |VCVTPS2PH xmm1/m64, xmm2,imm8
VEX.256.66.0F3A.W0 1D /r ib             |VCVTPS2PH xmm1/m128, ymm2,imm8
VERR/VERW—Verify
0F 00 /4                                |VERR r/m16
0F 00 /5                                |VERW r/m16
VEXTRACTF128/VEXTRACTF32x4/VEXTRACTF64x2/VEXTRACTF32x8/VEXTRACTF64x4—
VEX.256.66.0F3A.W0 19 /r ib             |VEXTRACTF128 xmm1/m128, ymm2,imm8
VEXTRACTI128/VEXTRACTI32x4/VEXTRACTI64x2/VEXTRACTI32x8/VEXTRACTI64x4—Extract
VEX.256.66.0F3A.W0 39 /r ib             |VEXTRACTI128 xmm1/m128, ymm2,imm8
VFMADD132PD/VFMADD213PD/VFMADD231PD—Fused
VEX.128.66.0F38.W1 98 /r                |VFMADD132PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 A8 /r                |VFMADD213PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 B8 /r                |VFMADD231PD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W1 98 /r                |VFMADD132PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 A8 /r                |VFMADD213PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 B8 /r                |VFMADD231PD ymm1, ymm2,ymm3/m256
VFMADD132PS/VFMADD213PS/VFMADD231PS—Fused
VEX.128.66.0F38.W0 98 /r                |VFMADD132PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 A8 /r                |VFMADD213PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 B8 /r                |VFMADD231PS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 98 /r                |VFMADD132PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 A8 /r                |VFMADD213PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.0 B8 /r                 |VFMADD231PS ymm1, ymm2,ymm3/m256
VFMADD132SD/VFMADD213SD/VFMADD231SD—Fused
VEX.LIG.66.0F38.W1 99 /r                |VFMADD132SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 A9 /r                |VFMADD213SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 B9 /r                |VFMADD231SD xmm1, xmm2,xmm3/m64
VFMADD132SS/VFMADD213SS/VFMADD231SS—Fused
VEX.LIG.66.0F38.W0 99 /r                |VFMADD132SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 A9 /r                |VFMADD213SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 B9 /r                |VFMADD231SS xmm1, xmm2,xmm3/m32
VFMADDSUB132PD/VFMADDSUB213PD/VFMADDSUB231PD—Fused
VEX.128.66.0F38.W1 96 /r                |VFMADDSUB132PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 A6 /r                |VFMADDSUB213PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 B6 /r                |VFMADDSUB231PD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W1 96 /r                |VFMADDSUB132PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 A6 /r                |VFMADDSUB213PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 B6 /r                |VFMADDSUB231PD ymm1, ymm2,ymm3/m256
VFMADDSUB132PS/VFMADDSUB213PS/VFMADDSUB231PS—Fused
VEX.128.66.0F38.W0 96 /r                |VFMADDSUB132PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 A6 /r                |VFMADDSUB213PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 B6 /r                |VFMADDSUB231PS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 96 /r                |VFMADDSUB132PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 A6 /r                |VFMADDSUB213PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 B6 /r                |VFMADDSUB231PS ymm1, ymm2,ymm3/m256
VFMSUB132PD/VFMSUB213PD/VFMSUB231PD—Fused
VEX.128.66.0F38.W1 9A /r                |VFMSUB132PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 AA /r                |VFMSUB213PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 BA /r                |VFMSUB231PD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W1 9A /r                |VFMSUB132PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 AA /r                |VFMSUB213PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 BA /r                |VFMSUB231PD ymm1, ymm2,ymm3/m256
VFMSUB132PS/VFMSUB213PS/VFMSUB231PS—Fused
VEX.128.66.0F38.W0 9A /r                |VFMSUB132PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 AA /r                |VFMSUB213PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 BA /r                |VFMSUB231PS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 9A /r                |VFMSUB132PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 AA /r                |VFMSUB213PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.0 BA /r                 |VFMSUB231PS ymm1, ymm2,ymm3/m256
VFMSUB132SD/VFMSUB213SD/VFMSUB231SD—Fused
VEX.LIG.66.0F38.W1 9B /r                |VFMSUB132SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 AB /r                |VFMSUB213SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 BB /r                |VFMSUB231SD xmm1, xmm2,xmm3/m64
VFMSUB132SS/VFMSUB213SS/VFMSUB231SS—Fused
VEX.LIG.66.0F38.W0 9B /r                |VFMSUB132SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 AB /r                |VFMSUB213SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 BB /r                |VFMSUB231SS xmm1, xmm2,xmm3/m32
VFMSUBADD132PD/VFMSUBADD213PD/VFMSUBADD231PD—Fused
VEX.128.66.0F38.W1 97 /r                |VFMSUBADD132PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 A7 /r                |VFMSUBADD213PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 B7 /r                |VFMSUBADD231PD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W1 97 /r                |VFMSUBADD132PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 A7 /r                |VFMSUBADD213PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 B7 /r                |VFMSUBADD231PD ymm1, ymm2,ymm3/m256
VFMSUBADD132PS/VFMSUBADD213PS/VFMSUBADD231PS—Fused
VEX.128.66.0F38.W0 97 /r                |VFMSUBADD132PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 A7 /r                |VFMSUBADD213PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 B7 /r                |VFMSUBADD231PS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 97 /r                |VFMSUBADD132PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 A7 /r                |VFMSUBADD213PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 B7 /r                |VFMSUBADD231PS ymm1, ymm2,ymm3/m256
VFNMADD132PD/VFNMADD213PD/VFNMADD231PD—Fused
VEX.128.66.0F38.W1 9C /r                |VFNMADD132PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 AC /r                |VFNMADD213PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 BC /r                |VFNMADD231PD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W1 9C /r                |VFNMADD132PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 AC /r                |VFNMADD213PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 BC /r                |VFNMADD231PD ymm1, ymm2,ymm3/m256
VFNMADD132PS/VFNMADD213PS/VFNMADD231PS—Fused
VEX.128.66.0F38.W0 9C /r                |VFNMADD132PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 AC /r                |VFNMADD213PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 BC /r                |VFNMADD231PS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 9C /r                |VFNMADD132PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 AC /r                |VFNMADD213PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.0 BC /r                 |VFNMADD231PS ymm1, ymm2,ymm3/m256
VFNMADD132SD/VFNMADD213SD/VFNMADD231SD—Fused
VEX.LIG.66.0F38.W1 9D /r                |VFNMADD132SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 AD /r                |VFNMADD213SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 BD /r                |VFNMADD231SD xmm1, xmm2,xmm3/m64
VFNMADD132SS/VFNMADD213SS/VFNMADD231SS—Fused
VEX.LIG.66.0F38.W0 9D /r                |VFNMADD132SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 AD /r                |VFNMADD213SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 BD /r                |VFNMADD231SS xmm1, xmm2,xmm3/m32
VFNMSUB132PD/VFNMSUB213PD/VFNMSUB231PD—Fused
VEX.128.66.0F38.W1 9E /r                |VFNMSUB132PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 AE /r                |VFNMSUB213PD xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W1 BE /r                |VFNMSUB231PD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W1 9E /r                |VFNMSUB132PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 AE /r                |VFNMSUB213PD ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W1 BE /r                |VFNMSUB231PD ymm1, ymm2,ymm3/m256
VFNMSUB132PS/VFNMSUB213PS/VFNMSUB231PS—Fused
VEX.128.66.0F38.W0 9E /r                |VFNMSUB132PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 AE /r                |VFNMSUB213PS xmm1, xmm2,xmm3/m128
VEX.128.66.0F38.W0 BE /r                |VFNMSUB231PS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 9E /r                |VFNMSUB132PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.W0 AE /r                |VFNMSUB213PS ymm1, ymm2,ymm3/m256
VEX.256.66.0F38.0 BE /r                 |VFNMSUB231PS ymm1, ymm2,ymm3/m256
VFNMSUB132SD/VFNMSUB213SD/VFNMSUB231SD—Fused
VEX.LIG.66.0F38.W1 9F /r                |VFNMSUB132SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 AF /r                |VFNMSUB213SD xmm1, xmm2,xmm3/m64
VEX.LIG.66.0F38.W1 BF /r                |VFNMSUB231SD xmm1, xmm2,xmm3/m64
VFNMSUB132SS/VFNMSUB213SS/VFNMSUB231SS—Fused
VEX.LIG.66.0F38.W0 9F /r                |VFNMSUB132SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 AF /r                |VFNMSUB213SS xmm1, xmm2,xmm3/m32
VEX.LIG.66.0F38.W0 BF /r                |VFNMSUB231SS xmm1, xmm2,xmm3/m32
VGATHERDPD/VGATHERQPD—Gather
VEX.128.66.0F38.W1 92 /r                |VGATHERDPD xmm1, vm32x, xmm2
VEX.128.66.0F38.W1 93 /r                |VGATHERQPD xmm1, vm64x, xmm2
VEX.256.66.0F38.W1 92 /r                |VGATHERDPD ymm1, vm32x, ymm2
VEX.256.66.0F38.W1 93 /r                |VGATHERQPD ymm1, vm64y, ymm2
VGATHERDPS/VGATHERQPS—Gather
VEX.128.66.0F38.W0 92 /r                |VGATHERDPS xmm1, vm32x, xmm2
VEX.128.66.0F38.W0 93 /r                |VGATHERQPS xmm1, vm64x, xmm2
VEX.256.66.0F38.W0 92 /r                |VGATHERDPS ymm1, vm32y, ymm2
VEX.256.66.0F38.W0 93 /r                |VGATHERQPS xmm1, vm64y, xmm2
VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4—Insert
VEX.256.66.0F3A.W0 18 /r ib             |VINSERTF128 ymm1, ymm2,xmm3/m128, imm8
VINSERTI128/VINSERTI32x4/VINSERTI64x2/VINSERTI32x8/VINSERTI64x4—Insert
VEX.256.66.0F3A.W0 38 /r ib             |VINSERTI128 ymm1, ymm2,xmm3/m128, imm8
VMASKMOV—Conditional
VEX.128.66.0F38.W0 2C /r                |VMASKMOVPS xmm1, xmm2, m128
VEX.256.66.0F38.W0 2C /r                |VMASKMOVPS ymm1, ymm2, m256
VEX.128.66.0F38.W0 2D /r                |VMASKMOVPD xmm1, xmm2, m128
VEX.256.66.0F38.W0 2D /r                |VMASKMOVPD ymm1, ymm2, m256
VEX.128.66.0F38.W0 2E /r                |VMASKMOVPS m128, xmm1, xmm2
VEX.256.66.0F38.W0 2E /r                |VMASKMOVPS m256, ymm1, ymm2
VEX.128.66.0F38.W0 2F /r                |VMASKMOVPD m128, xmm1, xmm2
VEX.256.66.0F38.W0 2F /r                |VMASKMOVPD m256, ymm1, ymm2
VPBLENDD—Blend
VEX.128.66.0F3A.W0 02 /r ib             |VPBLENDD xmm1, xmm2, xmm3/m128, imm8
VEX.256.66.0F3A.W0 02 /r ib             |VPBLENDD ymm1, ymm2, ymm3/m256, imm8
VPBROADCAST—Load
VEX.128.66.0F38.W0 78 /r                |VPBROADCASTB xmm1, xmm2/m8
VEX.256.66.0F38.W0 78 /r                |VPBROADCASTB ymm1, xmm2/m8
VEX.128.66.0F38.W0 79 /r                |VPBROADCASTW xmm1, xmm2/m16
VEX.256.66.0F38.W0 79 /r                |VPBROADCASTW ymm1, xmm2/m16
VEX.128.66.0F38.W0 58 /r                |VPBROADCASTD xmm1, xmm2/m32
VEX.256.66.0F38.W0 58 /r                |VPBROADCASTD ymm1, xmm2/m32
VEX.128.66.0F38.W0 59 /r                |VPBROADCASTQ xmm1, xmm2/m64
VEX.256.66.0F38.W0 59 /r                |VPBROADCASTQ ymm1, xmm2/m64
VPBROADCAST—Load
VEX.256.66.0F38.W0 5A /r                |VBROADCASTI128 ymm1, m128
VPDPBUSD—Multiply
VEX.128.66.0F38.W0 50 /r                |VPDPBUSD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 50 /r                |VPDPBUSD ymm1, ymm2,ymm3/m256
VPDPBUSDS—Multiply
VEX.128.66.0F38.W0 51 /r                |VPDPBUSDS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 51 /r                |VPDPBUSDS ymm1, ymm2,ymm3/m256
VPDPWSSD—Multiply
VEX.128.66.0F38.W0 52 /r                |VPDPWSSD xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 52 /r                |VPDPWSSD ymm1, ymm2,ymm3/m256
VPDPWSSDS—Multiply
VEX.128.66.0F38.W0 53 /r                |VPDPWSSDS xmm1, xmm2,xmm3/m128
VEX.256.66.0F38.W0 53 /r                |VPDPWSSDS ymm1, ymm2,ymm3/m256
VPERM2F128—Permute
VEX.256.66.0F3A.W0 06 /r ib             |VPERM2F128 ymm1, ymm2, ymm3/m256, imm8
VPERM2I128—Permute
VEX.256.66.0F3A.W0 46 /r ib             |VPERM2I128 ymm1, ymm2, ymm3/m256, imm8
VPERMD/VPERMW—Permute
VEX.256.66.0F38.W0 36 /r                |VPERMD ymm1, ymm2, ymm3/m256
VPERMILPD—Permute
VEX.128.66.0F38.W0 0D /r                |VPERMILPD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.W0 0D /r                |VPERMILPD ymm1, ymm2, ymm3/m256
VEX.128.66.0F3A.W0 05 /r ib             |VPERMILPD xmm1, xmm2/m128, imm8
VEX.256.66.0F3A.W0 05 /r ib             |VPERMILPD ymm1, ymm2/m256, imm8
VPERMILPS—Permute
VEX.128.66.0F38.W0 0C /r                |VPERMILPS xmm1, xmm2, xmm3/m128
VEX.128.66.0F3A.W0 04 /r ib             |VPERMILPS xmm1, xmm2/m128, imm8
VEX.256.66.0F38.W0 0C /r                |VPERMILPS ymm1, ymm2, ymm3/m256
VEX.256.66.0F3A.W0 04 /r ib             |VPERMILPS ymm1, ymm2/m256, imm8
VPERMPD—Permute
VEX.256.66.0F3A.W1 01 /r ib             |VPERMPD ymm1, ymm2/m256, imm8
VPERMPS—Permute
VEX.256.66.0F38.W0 16 /r                |VPERMPS ymm1, ymm2,ymm3/m256
VPERMQ—Qwords
VEX.256.66.0F3A.W1 00 /r ib             |VPERMQ ymm1, ymm2/m256, imm8
VPGATHERDD/VPGATHERQD—Gather
VEX.128.66.0F38.W0 90 /r                |VPGATHERDD xmm1, vm32x, xmm2
VEX.128.66.0F38.W0 91 /r                |VPGATHERQD xmm1, vm64x, xmm2
VEX.256.66.0F38.W0 90 /r                |VPGATHERDD ymm1, vm32y, ymm2
VEX.256.66.0F38.W0 91 /r                |VPGATHERQD xmm1, vm64y, xmm2
VPGATHERDQ/VPGATHERQQ—Gather
VEX.128.66.0F38.W1 90 /r                |VPGATHERDQ xmm1, vm32x, xmm2
VEX.128.66.0F38.W1 91 /r                |VPGATHERQQ xmm1, vm64x, xmm2
VEX.256.66.0F38.W1 90 /r                |VPGATHERDQ ymm1, vm32x, ymm2
VEX.256.66.0F38.W1 91 /r                |VPGATHERQQ ymm1, vm64y, ymm2
VPMASKMOV—Conditional
VEX.128.66.0F38.W0 8C /r                |VPMASKMOVD xmm1, xmm2, m128
VEX.256.66.0F38.W0 8C /r                |VPMASKMOVD ymm1, ymm2, m256
VEX.128.66.0F38.W1 8C /r                |VPMASKMOVQ xmm1, xmm2, m128
VEX.256.66.0F38.W1 8C /r                |VPMASKMOVQ ymm1, ymm2, m256
VEX.128.66.0F38.W0 8E /r                |VPMASKMOVD m128, xmm1, xmm2
VEX.256.66.0F38.W0 8E /r                |VPMASKMOVD m256, ymm1, ymm2
VEX.128.66.0F38.W1 8E /r                |VPMASKMOVQ m128, xmm1, xmm2
VEX.256.66.0F38.W1 8E /r                |VPMASKMOVQ m256, ymm1, ymm2
VPSLLVW/VPSLLVD/VPSLLVQ—Variable
VEX.128.66.0F38.W0 47 /r                |VPSLLVD xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.W1 47 /r                |VPSLLVQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.W0 47 /r                |VPSLLVD ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.W1 47 /r                |VPSLLVQ ymm1, ymm2, ymm3/m256
VPSRAVW/VPSRAVD/VPSRAVQ—Variable
VEX.128.66.0F38.W0 46 /r                |VPSRAVD xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.W0 46 /r                |VPSRAVD ymm1, ymm2, ymm3/m256
VPSRLVW/VPSRLVD/VPSRLVQ—Variable
VEX.128.66.0F38.W0 45 /r                |VPSRLVD xmm1, xmm2, xmm3/m128
VEX.128.66.0F38.W1 45 /r                |VPSRLVQ xmm1, xmm2, xmm3/m128
VEX.256.66.0F38.W0 45 /r                |VPSRLVD ymm1, ymm2, ymm3/m256
VEX.256.66.0F38.W1 45 /r                |VPSRLVQ ymm1, ymm2, ymm3/m256
VTESTPD/VTESTPS—Packed
VEX.128.66.0F38.W0 0E /r                |VTESTPS xmm1, xmm2/m128
VEX.256.66.0F38.W0 0E /r                |VTESTPS ymm1, ymm2/m256
VEX.128.66.0F38.W0 0F /r                |VTESTPD xmm1, xmm2/m128
VEX.256.66.0F38.W0 0F /r                |VTESTPD ymm1, ymm2/m256
VZEROALL—Zero
VEX.256.0F.WIG 77                       |VZEROALL
VZEROUPPER—Zero
VEX.128.0F.WIG 77                       |VZEROUPPER
WAIT/FWAIT—Wait
9B                                      |WAIT
9B                                      |FWAIT
WBINVD—Write
0F 09                                   |WBINVD
WBNOINVD—Write
F3 0F 09                                |WBNOINVD
WRFSBASE/WRGSBASE—Write
F3 0F AE /2                             |WRFSBASE r32
F3 REX.W 0F AE /2                       |WRFSBASE r64
F3 0F AE /3                             |WRGSBASE r32
F3 REX.W 0F AE /3                       |WRGSBASE r64
WRMSR—Write
0F 30                                   |WRMSR
WRPKRU—Write
NP 0F 01 EF                             |WRPKRU
WRSSD/WRSSQ—Write
0F 38 F6 !(11):rrr:bbb                  |WRSSD m32, r32
REX.W 0F 38 F6 !(11):rrr:bbb            |WRSSQ m64, r64
WRUSSD/WRUSSQ—Write
66 0F 38 F5 !(11):rrr:bbb               |WRUSSD m32, r32
66 REX.W 0F 38 F5 !(11):rrr:bbb         |WRUSSQ m64, r64
XABORT—Transactional
C6 F8 ib                                |XABORT imm8
XADD—Exchange
0F C0 /r                                |XADD r/m8, r8
REX + 0F C0 /r                          |XADD r/m8, r8
0F C1 /r                                |XADD r/m16, r16
0F C1 /r                                |XADD r/m32, r32
REX.W + 0F C1 /r                        |XADD r/m64, r64
XBEGIN—Transactional
C7 F8                                   |XBEGIN rel16
C7 F8                                   |XBEGIN rel32
XCHG—Exchange
90+rw                                   |XCHG AX, r16
90+rw                                   |XCHG r16, AX
90+rd                                   |XCHG EAX, r32
REX.W + 90+rd                           |XCHG RAX, r64
90+rd                                   |XCHG r32, EAX
REX.W + 90+rd                           |XCHG r64, RAX
86 /r                                   |XCHG r/m8, r8
REX + 86 /r                             |XCHG r/m8, r8
86 /r                                   |XCHG r8, r/m8
REX + 86 /r                             |XCHG r8, r/m8
87 /r                                   |XCHG r/m16, r16
87 /r                                   |XCHG r16, r/m16
87 /r                                   |XCHG r/m32, r32
REX.W + 87 /r                           |XCHG r/m64, r64
87 /r                                   |XCHG r32, r/m32
REX.W + 87 /r                           |XCHG r64, r/m64
XEND—Transactional
NP 0F 01 D5                             |XEND
XGETBV—Get
NP 0F 01 D0                             |XGETBV
XLAT/XLATB—Table
D7                                      |XLAT m8
D7                                      |XLATB
REX.W + D7                              |XLATB
XOR—Logical
34 ib                                   |XOR AL, imm8
35 iw                                   |XOR AX, imm16
35 id                                   |XOR EAX, imm32
REX.W + 35 id                           |XOR RAX, imm32
80 /6 ib                                |XOR r/m8, imm8
REX + 80 /6 ib                          |XOR r/m8, imm8
81 /6 iw                                |XOR r/m16, imm16
81 /6 id                                |XOR r/m32, imm32
REX.W + 81 /6 id                        |XOR r/m64, imm32
83 /6 ib                                |XOR r/m16, imm8
83 /6 ib                                |XOR r/m32, imm8
REX.W + 83 /6 ib                        |XOR r/m64, imm8
30 /r                                   |XOR r/m8, r8
REX + 30 /r                             |XOR r/m8, r8
31 /r                                   |XOR r/m16, r16
31 /r                                   |XOR r/m32, r32
REX.W + 31 /r                           |XOR r/m64, r64
32 /r                                   |XOR r8, r/m8
REX + 32 /r                             |XOR r8, r/m8
33 /r                                   |XOR r16, r/m16
33 /r                                   |XOR r32, r/m32
REX.W + 33 /r                           |XOR r64, r/m64
XORPD—Bitwise
66 0F 57/r                              |XORPD xmm1, xmm2/m128
VEX.128.66.0F.WIG 57 /r                 |VXORPD xmm1,xmm2, xmm3/m128
VEX.256.66.0F.WIG 57 /r                 |VXORPD ymm1, ymm2, ymm3/m256
XORPS—Bitwise
NP 0F 57 /r                             |XORPS xmm1, xmm2/m128
VEX.128.0F.WIG 57 /r                    |VXORPS xmm1,xmm2, xmm3/m128
VEX.256.0F.WIG 57 /r                    |VXORPS ymm1, ymm2, ymm3/m256
XRESLDTRK—Resume
F2 0F 01 E9                             |XRESLDTRK
XRSTOR—Restore
NP 0F AE /5                             |XRSTOR mem
NP REX.W + 0F AE /5                     |XRSTOR64 mem
XRSTORS—Restore
NP 0F C7 /3                             |XRSTORS mem
NP REX.W + 0F C7 /3                     |XRSTORS64 mem
XSAVE—Save
NP 0F AE /4                             |XSAVE mem
NP REX.W + 0F AE /4                     |XSAVE64 mem
XSAVEC—Save
NP 0F C7 /4                             |XSAVEC mem
NP REX.W + 0F C7 /4                     |XSAVEC64 mem
XSAVEOPT—Save
NP 0F AE /6                             |XSAVEOPT mem
NP REX.W + 0F AE /6                     |XSAVEOPT64 mem
XSAVES—Save
NP 0F C7 /5                             |XSAVES mem
NP REX.W + 0F C7 /5                     |XSAVES64 mem
XSETBV—Set
NP 0F 01 D1                             |XSETBV
XSUSLDTRK—Suspend
F2 0F 01 E8                             |XSUSLDTRK
XTEST—Test
NP 0F 01 D6                             |XTEST
